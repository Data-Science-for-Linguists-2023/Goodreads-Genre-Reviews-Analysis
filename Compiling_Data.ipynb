{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69233e18",
   "metadata": {},
   "source": [
    "# Compiling Data\n",
    "Ashley Feiler, aef56@pitt.edu\n",
    "\n",
    "New Continuing from Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5ee665",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a291f254",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7853563f",
   "metadata": {},
   "source": [
    "## Sharable Data Samples\n",
    "Because I can't share all of the data I'm using due to licensing, I plan on sharing samples. Since my computer could only handle loading so much data at a time, I used separate Jupyter Notebooks for different genres that I could open, merge the necessary data, pickle a smaller sample file, and then close, freeing memory. In this file, I will unpickle and combine all of those samples to then share."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4288a9b",
   "metadata": {},
   "source": [
    "### Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77832869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/ashleyfeiler/Documents/data_science/Goodreads-Genre-Reviews-Analysis/data/genre_share/fantasy_share.pkl'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = '/Users/ashleyfeiler/Documents/data_science/Goodreads-Genre-Reviews-Analysis/data/'\n",
    "\n",
    "share_files = glob.glob(directory + 'genre_share/*.pkl') #Get filepath of all pickled files\n",
    "print(len(share_files)) #Confirm 8 files for 8 genres\n",
    "share_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db42eecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 40 entries, 0 to 4\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   user_id       40 non-null     object\n",
      " 1   book_id       40 non-null     int64 \n",
      " 2   review_id     40 non-null     object\n",
      " 3   rating        40 non-null     int64 \n",
      " 4   review_text   40 non-null     object\n",
      " 5   date_added    40 non-null     object\n",
      " 6   date_updated  40 non-null     object\n",
      " 7   read_at       40 non-null     object\n",
      " 8   started_at    40 non-null     object\n",
      " 9   n_votes       40 non-null     int64 \n",
      " 10  n_comments    40 non-null     int64 \n",
      "dtypes: int64(4), object(7)\n",
      "memory usage: 3.8+ KB\n"
     ]
    }
   ],
   "source": [
    "share_df = pd.DataFrame() #Create empty DataFrame to append each genre's sample to\n",
    "\n",
    "for pkl in share_files: #For each file directory, load file and add to shared DataFrame\n",
    "    f = open(pkl, 'rb')  \n",
    "    df = pickle.load(f)     \n",
    "    f.close()  \n",
    "    share_df = pd.concat([share_df, df])\n",
    "    \n",
    "share_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788102b7",
   "metadata": {},
   "source": [
    "This confirms that all together, there are 40 review samples just like there were supposed to be (5 from 8 genres). To keep the sample as minimal as possible to stay within Fair Use guidelines, I will take a sample of only 5 of these 40 reviews to then save as a CSV and share in my public repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4253e2aa",
   "metadata": {},
   "source": [
    "(The code below that writes the CSV file has been commented out to prevent the CSV file from being overwritten every time this notebook is run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6bae7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#genre_samples = share_df.sample(5)\n",
    "#genre_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5f539c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#genre_samples.to_csv('data_samples/Genre_Samples.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a607d3a0",
   "metadata": {},
   "source": [
    "### Condensed Data\n",
    "That first process was to show a sample of what the original UCSD data looked like, but I also want to show the final format of data that I compiled and will be working with for my analysis. Below is the same process as above, but with the final DataFrames I created for each genre (each genre ranging from around 3000-4000 reviews). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01acbbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/ashleyfeiler/Documents/data_science/Goodreads-Genre-Reviews-Analysis/data/genre_pkls/children_short.pkl'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_files = glob.glob(directory + 'genre_pkls/*.pkl')\n",
    "print(len(genre_files))\n",
    "genre_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06c0397f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 28274 entries, 0 to 4998\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Text           28274 non-null  object \n",
      " 1   Rating         28274 non-null  int64  \n",
      " 2   Title          28274 non-null  object \n",
      " 3   Author         28274 non-null  object \n",
      " 4   Category       28274 non-null  object \n",
      " 5   Genres         28274 non-null  object \n",
      " 6   Language       28274 non-null  object \n",
      " 7   Pages          28274 non-null  object \n",
      " 8   Pub_Year       28274 non-null  object \n",
      " 9   Avg_Rating     28274 non-null  float64\n",
      " 10  Ratings_Count  28274 non-null  int64  \n",
      " 11  User_ID        28274 non-null  object \n",
      "dtypes: float64(1), int64(2), object(9)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "total_df = pd.DataFrame()\n",
    "\n",
    "for pkl in genre_files:\n",
    "    f = open(pkl, 'rb')  \n",
    "    df = pickle.load(f)     \n",
    "    f.close()  \n",
    "    total_df = pd.concat([total_df, df])\n",
    "    \n",
    "total_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501d2cc1",
   "metadata": {},
   "source": [
    "Combining the samples from all 8 genres resulted in a total of 28274 reviews in total, which is a pretty decent amount of data to work with! Further down I will get into some more exploration of the makeup of this final data set I will be working with, but for now I want to save a small sample of this DataFrame to share."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1471d1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_sample = total_df.sample(5)\n",
    "#total_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7df35eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_sample.to_csv('data_samples/FinalDF_Sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b670ea36",
   "metadata": {},
   "source": [
    "## Data Makeup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5565e4bd",
   "metadata": {},
   "source": [
    "At first I thought I might still need the userIDs, but I given all the columns I plan on adding for linguistic features, I don't think those IDs will be necessary, so my first order of business is to remove that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53bf46c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = total_df[['Text', 'Rating', 'Title', 'Author', 'Category', 'Genres', 'Language', 'Pages', 'Pub_Year', 'Avg_Rating', 'Ratings_Count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5fb362c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Text', 'Rating', 'Title', 'Author', 'Category', 'Genres', 'Language',\n",
       "       'Pages', 'Pub_Year', 'Avg_Rating', 'Ratings_Count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fc894c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = total_df.reset_index(drop=True)\n",
    "#Some reviews have the same indexes because they came from separate DataFrames, so this resets the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bbbec7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28274 entries, 0 to 28273\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Text           28274 non-null  object \n",
      " 1   Rating         28274 non-null  int64  \n",
      " 2   Title          28274 non-null  object \n",
      " 3   Author         28274 non-null  object \n",
      " 4   Category       28274 non-null  object \n",
      " 5   Genres         28274 non-null  object \n",
      " 6   Language       28274 non-null  object \n",
      " 7   Pages          28274 non-null  object \n",
      " 8   Pub_Year       28274 non-null  object \n",
      " 9   Avg_Rating     28274 non-null  float64\n",
      " 10  Ratings_Count  28274 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(8)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "total_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c7b2e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28274, 11)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bce6f7",
   "metadata": {},
   "source": [
    "I am working with a DataFrame of 28274 reviews and 11 total columns, though this will expand as I add more linguistic features.\n",
    "\n",
    "Now that that's done, let's take a look at some of the counts of different categories. What makeup of data am I finally working with?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd44e76c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ya                        4334\n",
       "fantasy_paranormal        4323\n",
       "romance                   3918\n",
       "mystery_thriller_crime    3789\n",
       "comics_graphic            3505\n",
       "history_bio               3362\n",
       "children                  2858\n",
       "poetry                    2185\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.Category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae41ee8d",
   "metadata": {},
   "source": [
    "Clearly there is a pretty wide range in the number of reviews left from each genre after some of the data cleaning. Each genre started out with 5000 reviews, but some were eliminated because they were non-English or empty, which disproportionately affected different genres. This will definitely be something to keep in mind during analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a0775a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    9941\n",
       "4    9593\n",
       "3    5356\n",
       "2    1807\n",
       "0     894\n",
       "1     683\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.Rating.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69efb9e9",
   "metadata": {},
   "source": [
    "5- and 4-star reviews are by far the most common, followed by 3-star reviews. 2-star reviews are much less frequent, and 0- and 1-star reviews even less. It makes sense that the higher ratings are more common as people are more likely to write a review about a book they like rather than a book they are indifferent about, but I'm a little surprised to see so few low ratings. In my experience, people tend to be pretty passionate about books they hate as well. If genre turns out to not be a significant factor changing linguistic features, it could be interesting to see if rating, which theoretically correlates to sentiment, has any effect on the language used in the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "195a8e33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17774"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_df.Title.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4198b71c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Milk and Honey                                                                          113\n",
       "Hamlet                                                                                   50\n",
       "The Giver (The Giver, #1)                                                                50\n",
       "The Hunger Games (The Hunger Games, #1)                                                  49\n",
       "Cinder (The Lunar Chronicles, #1)                                                        49\n",
       "The Girl on the Train                                                                    47\n",
       "Brown Girl Dreaming                                                                      44\n",
       "Wonder (Wonder #1)                                                                       43\n",
       "Miss Peregrine’s Home for Peculiar Children (Miss Peregrine’s Peculiar Children, #1)     42\n",
       "Divergent (Divergent, #1)                                                                40\n",
       "Where the Sidewalk Ends                                                                  40\n",
       "Gone Girl                                                                                37\n",
       "City of Bones (The Mortal Instruments, #1)                                               37\n",
       "Throne of Glass (Throne of Glass, #1)                                                    37\n",
       "The Fault in Our Stars                                                                   35\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.Title.value_counts()[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f4e4d5",
   "metadata": {},
   "source": [
    "Out of 28274 reviews, there are 17774 unique book titles that are reviewed, meaning 10500 reviews are repeat reviews of at least one book (a suspiciously even number), but still the majority of books are only reviewed once. Milk and Honey, a very popular book of poetry, is the most reviewed book at 113 reviews, and a lot of the other most reviewed books I recognize as Young Adult and Fantasy novels. Those were the top 2 genres with the most reviews that made the final cut, so it's not surprising there are more repeat reviews for these books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "078f8bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9688"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_df.Author.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c2d1852",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cassandra Clare     250\n",
       "Brian K. Vaughan    157\n",
       "Neil Gaiman         148\n",
       "Marissa Meyer       137\n",
       "Stephenie Meyer     130\n",
       "Rupi Kaur           127\n",
       "Sarah J. Maas       123\n",
       "Stephen King        123\n",
       "Rick Riordan        115\n",
       "Suzanne Collins     106\n",
       "Name: Author, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.Author.value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbe09b3",
   "metadata": {},
   "source": [
    "Out of 28274 reviews, there are only 9688 authors that are reviewed, which is a smaller number, but makes sense seeing as authors may have written many different books. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f4c49dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eng      22737\n",
       "en-US     4268\n",
       "en-GB     1026\n",
       "en-CA      243\n",
       "Name: Language, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.Language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87f8c4b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Avg_Rating</th>\n",
       "      <th>Ratings_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28274.000000</td>\n",
       "      <td>28274.000000</td>\n",
       "      <td>2.827400e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.835396</td>\n",
       "      <td>3.990835</td>\n",
       "      <td>8.802585e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.221860</td>\n",
       "      <td>0.292023</td>\n",
       "      <td>3.506487e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.980000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.810000</td>\n",
       "      <td>5.360000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>4.224000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.190000</td>\n",
       "      <td>3.052450e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.899965e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Rating    Avg_Rating  Ratings_Count\n",
       "count  28274.000000  28274.000000   2.827400e+04\n",
       "mean       3.835396      3.990835   8.802585e+04\n",
       "std        1.221860      0.292023   3.506487e+05\n",
       "min        0.000000      1.980000   0.000000e+00\n",
       "25%        3.000000      3.810000   5.360000e+02\n",
       "50%        4.000000      4.010000   4.224000e+03\n",
       "75%        5.000000      4.190000   3.052450e+04\n",
       "max        5.000000      5.000000   4.899965e+06"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bff97fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">Rating</th>\n",
       "      <th colspan=\"5\" halign=\"left\">Avg_Rating</th>\n",
       "      <th colspan=\"8\" halign=\"left\">Ratings_Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>children</th>\n",
       "      <td>2858.0</td>\n",
       "      <td>3.904829</td>\n",
       "      <td>1.203209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2858.0</td>\n",
       "      <td>4.037768</td>\n",
       "      <td>...</td>\n",
       "      <td>4.21</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2858.0</td>\n",
       "      <td>93980.546186</td>\n",
       "      <td>275095.225792</td>\n",
       "      <td>1.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>3001.5</td>\n",
       "      <td>31387.00</td>\n",
       "      <td>1876252.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comics_graphic</th>\n",
       "      <td>3505.0</td>\n",
       "      <td>3.811412</td>\n",
       "      <td>1.153754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3505.0</td>\n",
       "      <td>4.021680</td>\n",
       "      <td>...</td>\n",
       "      <td>4.24</td>\n",
       "      <td>4.83</td>\n",
       "      <td>3505.0</td>\n",
       "      <td>16528.807703</td>\n",
       "      <td>41517.096041</td>\n",
       "      <td>1.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>2705.0</td>\n",
       "      <td>12834.00</td>\n",
       "      <td>406669.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fantasy_paranormal</th>\n",
       "      <td>4323.0</td>\n",
       "      <td>3.816100</td>\n",
       "      <td>1.246819</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4323.0</td>\n",
       "      <td>4.014464</td>\n",
       "      <td>...</td>\n",
       "      <td>4.23</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4323.0</td>\n",
       "      <td>108879.451076</td>\n",
       "      <td>375846.839796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>838.5</td>\n",
       "      <td>7755.0</td>\n",
       "      <td>55039.00</td>\n",
       "      <td>4765497.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>history_bio</th>\n",
       "      <td>3362.0</td>\n",
       "      <td>3.851279</td>\n",
       "      <td>1.215740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3362.0</td>\n",
       "      <td>3.943968</td>\n",
       "      <td>...</td>\n",
       "      <td>4.14</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3362.0</td>\n",
       "      <td>96545.556217</td>\n",
       "      <td>342835.065977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>592.0</td>\n",
       "      <td>4165.0</td>\n",
       "      <td>30058.75</td>\n",
       "      <td>3255518.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mystery_thriller_crime</th>\n",
       "      <td>3789.0</td>\n",
       "      <td>3.727105</td>\n",
       "      <td>1.178367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3789.0</td>\n",
       "      <td>3.884130</td>\n",
       "      <td>...</td>\n",
       "      <td>4.06</td>\n",
       "      <td>4.88</td>\n",
       "      <td>3789.0</td>\n",
       "      <td>59168.214568</td>\n",
       "      <td>210601.102517</td>\n",
       "      <td>1.0</td>\n",
       "      <td>522.0</td>\n",
       "      <td>3984.0</td>\n",
       "      <td>22034.00</td>\n",
       "      <td>2046499.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poetry</th>\n",
       "      <td>2185.0</td>\n",
       "      <td>3.897941</td>\n",
       "      <td>1.276413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2185.0</td>\n",
       "      <td>4.096256</td>\n",
       "      <td>...</td>\n",
       "      <td>4.26</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2185.0</td>\n",
       "      <td>44478.507551</td>\n",
       "      <td>151734.841123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>1433.0</td>\n",
       "      <td>15270.00</td>\n",
       "      <td>1029527.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>romance</th>\n",
       "      <td>3918.0</td>\n",
       "      <td>3.943849</td>\n",
       "      <td>1.212399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3918.0</td>\n",
       "      <td>4.000403</td>\n",
       "      <td>...</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.91</td>\n",
       "      <td>3918.0</td>\n",
       "      <td>32528.685299</td>\n",
       "      <td>143318.963490</td>\n",
       "      <td>1.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>1878.5</td>\n",
       "      <td>10393.00</td>\n",
       "      <td>2078406.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ya</th>\n",
       "      <td>4334.0</td>\n",
       "      <td>3.781034</td>\n",
       "      <td>1.272587</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4334.0</td>\n",
       "      <td>3.979213</td>\n",
       "      <td>...</td>\n",
       "      <td>4.17</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4334.0</td>\n",
       "      <td>211864.244347</td>\n",
       "      <td>652314.359248</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2863.5</td>\n",
       "      <td>19151.0</td>\n",
       "      <td>106182.00</td>\n",
       "      <td>4899965.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Rating                                               \\\n",
       "                         count      mean       std  min  25%  50%  75%  max   \n",
       "Category                                                                      \n",
       "children                2858.0  3.904829  1.203209  0.0  3.0  4.0  5.0  5.0   \n",
       "comics_graphic          3505.0  3.811412  1.153754  0.0  3.0  4.0  5.0  5.0   \n",
       "fantasy_paranormal      4323.0  3.816100  1.246819  0.0  3.0  4.0  5.0  5.0   \n",
       "history_bio             3362.0  3.851279  1.215740  0.0  3.0  4.0  5.0  5.0   \n",
       "mystery_thriller_crime  3789.0  3.727105  1.178367  0.0  3.0  4.0  5.0  5.0   \n",
       "poetry                  2185.0  3.897941  1.276413  0.0  3.0  4.0  5.0  5.0   \n",
       "romance                 3918.0  3.943849  1.212399  0.0  3.0  4.0  5.0  5.0   \n",
       "ya                      4334.0  3.781034  1.272587  0.0  3.0  4.0  5.0  5.0   \n",
       "\n",
       "                       Avg_Rating            ...             Ratings_Count  \\\n",
       "                            count      mean  ...   75%   max         count   \n",
       "Category                                     ...                             \n",
       "children                   2858.0  4.037768  ...  4.21  5.00        2858.0   \n",
       "comics_graphic             3505.0  4.021680  ...  4.24  4.83        3505.0   \n",
       "fantasy_paranormal         4323.0  4.014464  ...  4.23  5.00        4323.0   \n",
       "history_bio                3362.0  3.943968  ...  4.14  5.00        3362.0   \n",
       "mystery_thriller_crime     3789.0  3.884130  ...  4.06  4.88        3789.0   \n",
       "poetry                     2185.0  4.096256  ...  4.26  5.00        2185.0   \n",
       "romance                    3918.0  4.000403  ...  4.20  4.91        3918.0   \n",
       "ya                         4334.0  3.979213  ...  4.17  5.00        4334.0   \n",
       "\n",
       "                                                                            \\\n",
       "                                 mean            std  min     25%      50%   \n",
       "Category                                                                     \n",
       "children                 93980.546186  275095.225792  1.0   330.0   3001.5   \n",
       "comics_graphic           16528.807703   41517.096041  1.0   479.0   2705.0   \n",
       "fantasy_paranormal      108879.451076  375846.839796  1.0   838.5   7755.0   \n",
       "history_bio              96545.556217  342835.065977  0.0   592.0   4165.0   \n",
       "mystery_thriller_crime   59168.214568  210601.102517  1.0   522.0   3984.0   \n",
       "poetry                   44478.507551  151734.841123  0.0   148.0   1433.0   \n",
       "romance                  32528.685299  143318.963490  1.0   333.0   1878.5   \n",
       "ya                      211864.244347  652314.359248  1.0  2863.5  19151.0   \n",
       "\n",
       "                                              \n",
       "                              75%        max  \n",
       "Category                                      \n",
       "children                 31387.00  1876252.0  \n",
       "comics_graphic           12834.00   406669.0  \n",
       "fantasy_paranormal       55039.00  4765497.0  \n",
       "history_bio              30058.75  3255518.0  \n",
       "mystery_thriller_crime   22034.00  2046499.0  \n",
       "poetry                   15270.00  1029527.0  \n",
       "romance                  10393.00  2078406.0  \n",
       "ya                      106182.00  4899965.0  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.groupby('Category').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7764f4d6",
   "metadata": {},
   "source": [
    "The mean ratings for each genre are pretty close together, but Romance has the highest average rating of 3.94 and Mystery/Thriller/Crime has the lowest average rating of 3.73. It's also intersting to compare the average ratings from these reviews to the Avg_Rating column statistics, which is the average rating of the book being reviewed. In general, the sample of reviews I am analyzing rate the book slightly lower than its average rating from all reviews, which is just an interesting phenomenon. Finally, the ratings count shows the number of ratings each book had (again, not just the UCSD data), so it appears that the books of the Young Adult genre represented by the UCSD corpus has by far the most ratings on Goodreads (211864) and books of the Comics/Graphic genre have the least (16529). It could be interesting to look at genres with a lower ratings count but higher reviews count, which suggests that it is a more niche genre that appeals to a more specific type of reader."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afba00e",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "Now that I've FINALLY got my final data set and a sense of its size and makeup, it's time to start analysis! Since I'm looking at overall linguistic differences between reviews for different genres, I want to include as many different linguistic features as I can think of. In this next secion, I will be adding those features as additional columns to the DataFrame so I can then analayze their differences between genre categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f154dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "%pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4853d09",
   "metadata": {},
   "source": [
    "### Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fdd895",
   "metadata": {},
   "source": [
    "For each feature, I'm going to test first on a small subset of the reviews before applying the changes to the full DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10ac2242",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j9/9lmff3zj6bxgfpsb8gm8pjrw0000gn/T/ipykernel_37260/19419265.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['Toks'] = test_df.Text.map(nltk.word_tokenize)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                                  [O]\n",
       "1        [my, pick, for, the, caldecott, so, far, ...]\n",
       "2    [This, time, Dan, and, Amy, go, to, the, Baham...\n",
       "3    [Loved, the, excerpts, where, Julia, ,, the, m...\n",
       "4    [I, liked, the, illustrations, ,, which, are, ...\n",
       "Name: Toks, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = total_df.head()\n",
    "test_df['Toks'] = test_df.Text.map(nltk.word_tokenize)\n",
    "test_df['Toks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f21c38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Category</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Language</th>\n",
       "      <th>Pages</th>\n",
       "      <th>Pub_Year</th>\n",
       "      <th>Avg_Rating</th>\n",
       "      <th>Ratings_Count</th>\n",
       "      <th>Toks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>Xander's Panda Party</td>\n",
       "      <td>Linda Sue Park</td>\n",
       "      <td>children</td>\n",
       "      <td>{'children': 143, 'fiction': 15, 'poetry': 9, ...</td>\n",
       "      <td>eng</td>\n",
       "      <td>40</td>\n",
       "      <td>2013</td>\n",
       "      <td>4.05</td>\n",
       "      <td>1163</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my pick for the caldecott so far...</td>\n",
       "      <td>5</td>\n",
       "      <td>Xander's Panda Party</td>\n",
       "      <td>Linda Sue Park</td>\n",
       "      <td>children</td>\n",
       "      <td>{'children': 143, 'fiction': 15, 'poetry': 9, ...</td>\n",
       "      <td>eng</td>\n",
       "      <td>40</td>\n",
       "      <td>2013</td>\n",
       "      <td>4.05</td>\n",
       "      <td>1163</td>\n",
       "      <td>[my, pick, for, the, caldecott, so, far, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This time Dan and Amy go to the Bahamas and Ja...</td>\n",
       "      <td>4</td>\n",
       "      <td>Storm Warning (The 39 Clues, #9)</td>\n",
       "      <td>Linda Sue Park</td>\n",
       "      <td>children</td>\n",
       "      <td>{'mystery, thriller, crime': 188, 'young-adult...</td>\n",
       "      <td>eng</td>\n",
       "      <td>190</td>\n",
       "      <td>2010</td>\n",
       "      <td>3.98</td>\n",
       "      <td>39904</td>\n",
       "      <td>[This, time, Dan, and, Amy, go, to, the, Baham...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Loved the excerpts where Julia, the main chara...</td>\n",
       "      <td>5</td>\n",
       "      <td>Project Mulberry</td>\n",
       "      <td>Linda Sue Park</td>\n",
       "      <td>children</td>\n",
       "      <td>{'fiction': 122, 'children': 111, 'young-adult...</td>\n",
       "      <td>eng</td>\n",
       "      <td>240</td>\n",
       "      <td>2007</td>\n",
       "      <td>3.67</td>\n",
       "      <td>2929</td>\n",
       "      <td>[Loved, the, excerpts, where, Julia, ,, the, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I liked the illustrations, which are are - wel...</td>\n",
       "      <td>4</td>\n",
       "      <td>A Moon of My Own</td>\n",
       "      <td>Jennifer Rustgi</td>\n",
       "      <td>children</td>\n",
       "      <td>{'children': 13, 'young-adult': 2, 'non-fictio...</td>\n",
       "      <td>eng</td>\n",
       "      <td>32</td>\n",
       "      <td>2016</td>\n",
       "      <td>3.78</td>\n",
       "      <td>84</td>\n",
       "      <td>[I, liked, the, illustrations, ,, which, are, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Rating  \\\n",
       "0                                                  O       0   \n",
       "1                my pick for the caldecott so far...       5   \n",
       "2  This time Dan and Amy go to the Bahamas and Ja...       4   \n",
       "3  Loved the excerpts where Julia, the main chara...       5   \n",
       "4  I liked the illustrations, which are are - wel...       4   \n",
       "\n",
       "                              Title           Author  Category  \\\n",
       "0              Xander's Panda Party   Linda Sue Park  children   \n",
       "1              Xander's Panda Party   Linda Sue Park  children   \n",
       "2  Storm Warning (The 39 Clues, #9)   Linda Sue Park  children   \n",
       "3                  Project Mulberry   Linda Sue Park  children   \n",
       "4                  A Moon of My Own  Jennifer Rustgi  children   \n",
       "\n",
       "                                              Genres Language Pages Pub_Year  \\\n",
       "0  {'children': 143, 'fiction': 15, 'poetry': 9, ...      eng    40     2013   \n",
       "1  {'children': 143, 'fiction': 15, 'poetry': 9, ...      eng    40     2013   \n",
       "2  {'mystery, thriller, crime': 188, 'young-adult...      eng   190     2010   \n",
       "3  {'fiction': 122, 'children': 111, 'young-adult...      eng   240     2007   \n",
       "4  {'children': 13, 'young-adult': 2, 'non-fictio...      eng    32     2016   \n",
       "\n",
       "   Avg_Rating  Ratings_Count  \\\n",
       "0        4.05           1163   \n",
       "1        4.05           1163   \n",
       "2        3.98          39904   \n",
       "3        3.67           2929   \n",
       "4        3.78             84   \n",
       "\n",
       "                                                Toks  \n",
       "0                                                [O]  \n",
       "1      [my, pick, for, the, caldecott, so, far, ...]  \n",
       "2  [This, time, Dan, and, Amy, go, to, the, Baham...  \n",
       "3  [Loved, the, excerpts, where, Julia, ,, the, m...  \n",
       "4  [I, liked, the, illustrations, ,, which, are, ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df['Toks'] = total_df.Text.map(nltk.word_tokenize)\n",
    "total_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f628ee82",
   "metadata": {},
   "source": [
    "I want to add a lowercased tokenized column which may help keep things consistent for future calculations, but I want to make that in addition to the first 'Toks' column because capitalization could be an interesting feature to look at as well.\n",
    "\n",
    "Also, I am still trying to avoid flashing the head of the DataFrame too frequently to avoid sharing more data than I should."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "903f076f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j9/9lmff3zj6bxgfpsb8gm8pjrw0000gn/T/ipykernel_37260/780036847.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['Toks_Lower'] = test_df.Toks.map(lambda x: [word.lower() for word in x])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                                  [o]\n",
       "1        [my, pick, for, the, caldecott, so, far, ...]\n",
       "2    [this, time, dan, and, amy, go, to, the, baham...\n",
       "3    [loved, the, excerpts, where, julia, ,, the, m...\n",
       "4    [i, liked, the, illustrations, ,, which, are, ...\n",
       "Name: Toks_Lower, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Toks_Lower'] = test_df.Toks.map(lambda x: [word.lower() for word in x])\n",
    "test_df['Toks_Lower']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb842eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df['Toks_Lower'] = total_df.Toks.map(lambda x: [word.lower() for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8635220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'time', 'dan', 'and', 'amy', 'go', 'to', 'the', 'bahamas', 'and', 'jamaica', 'to', 'discover', 'the', 'truth', 'about', 'the', 'madrigals', '.', 'they', 'find', 'the', 'clue', 'to', 'the', 'next', 'country', 'which', 'may', 'yet', 'unify', 'the', 'cahills', 'once', 'again']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.Toks_Lower.iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a5aca3",
   "metadata": {},
   "source": [
    "Looks good!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78af50e1",
   "metadata": {},
   "source": [
    "### Token Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be63de2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j9/9lmff3zj6bxgfpsb8gm8pjrw0000gn/T/ipykernel_37260/1246011675.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['Tok_Count'] = test_df.Toks.map(len)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      8\n",
       "2     35\n",
       "3     18\n",
       "4    153\n",
       "Name: Tok_Count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Tok_Count'] = test_df.Toks.map(len)\n",
    "test_df['Tok_Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e15dee82",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df['Tok_Count'] = total_df.Toks.map(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc072d5b",
   "metadata": {},
   "source": [
    "### Word Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01e68cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j9/9lmff3zj6bxgfpsb8gm8pjrw0000gn/T/ipykernel_37260/1128489747.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['Avg_Word_Len'] = test_df.Toks.map(lambda x: np.mean([len(w) for w in x if w.isalnum()]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1.000000\n",
       "1    3.714286\n",
       "2    4.176471\n",
       "3    5.000000\n",
       "4    4.484375\n",
       "Name: Avg_Word_Len, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Excludes punctuation for this category (could bring down average word length inaccurately)\n",
    "test_df['Avg_Word_Len'] = test_df.Toks.map(lambda x: np.mean([len(w) for w in x if w.isalnum()]))\n",
    "test_df['Avg_Word_Len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e87ce0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my', 'pick', 'for', 'the', 'caldecott', 'so', 'far', '...']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.Toks.iloc[1] #Checking the math on my own - looks correct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "646967d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashleyfeiler/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/ashleyfeiler/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "total_df['Avg_Word_Len'] = total_df.Toks.map(lambda x: np.mean([len(w) for w in x if w.isalnum()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735e3e22",
   "metadata": {},
   "source": [
    "### Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4fcee793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j9/9lmff3zj6bxgfpsb8gm8pjrw0000gn/T/ipykernel_37260/738031235.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['Sents'] = test_df.Text.map(nltk.sent_tokenize)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                                  [O]\n",
       "1                [my pick for the caldecott so far...]\n",
       "2    [This time Dan and Amy go to the Bahamas and J...\n",
       "3    [Loved the excerpts where Julia, the main char...\n",
       "4    [I liked the illustrations, which are are - we...\n",
       "Name: Sents, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Sents'] = test_df.Text.map(nltk.sent_tokenize)\n",
    "test_df['Sents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "302dae5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This time Dan and Amy go to the Bahamas and Jamaica to discover the truth about the Madrigals.', 'They find the clue to the next country which may yet unify the Cahills once again']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.Sents.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "857d1343",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df['Sents'] = total_df.Text.map(nltk.sent_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f60a351",
   "metadata": {},
   "source": [
    "### Sentence Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e48af4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j9/9lmff3zj6bxgfpsb8gm8pjrw0000gn/T/ipykernel_37260/1611349258.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['Sents_Count'] = test_df.Sents.map(len)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    2\n",
       "3    1\n",
       "4    5\n",
       "Name: Sents_Count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Sents_Count'] = test_df.Sents.map(len)\n",
    "test_df['Sents_Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5293db9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df['Sents_Count'] = total_df.Sents.map(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a9acd0",
   "metadata": {},
   "source": [
    "### Sentence Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a7fc3541",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j9/9lmff3zj6bxgfpsb8gm8pjrw0000gn/T/ipykernel_37260/17652353.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['Avg_Sent_Len'] = test_df.Sents.map(lambda x: np.mean([len(nltk.word_tokenize(s)) for s in x]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     1.0\n",
       "1     8.0\n",
       "2    17.5\n",
       "3    18.0\n",
       "4    30.6\n",
       "Name: Avg_Sent_Len, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Had to tokenize first\n",
    "test_df['Avg_Sent_Len'] = test_df.Sents.map(lambda x: np.mean([len(nltk.word_tokenize(s)) for s in x]))\n",
    "test_df['Avg_Sent_Len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "68d800f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df['Avg_Sent_Len'] = total_df.Sents.map(lambda x: np.mean([len(nltk.word_tokenize(s)) for s in x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b735fdf",
   "metadata": {},
   "source": [
    "I've added a decent number of features, so let's check in with the `.describe()` feature to see where the numbers stand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "462ac21d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Avg_Rating</th>\n",
       "      <th>Ratings_Count</th>\n",
       "      <th>Tok_Count</th>\n",
       "      <th>Avg_Word_Len</th>\n",
       "      <th>Sents_Count</th>\n",
       "      <th>Avg_Sent_Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28274.000000</td>\n",
       "      <td>28274.000000</td>\n",
       "      <td>2.827400e+04</td>\n",
       "      <td>28274.000000</td>\n",
       "      <td>28118.000000</td>\n",
       "      <td>28274.000000</td>\n",
       "      <td>28274.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.835396</td>\n",
       "      <td>3.990835</td>\n",
       "      <td>8.802585e+04</td>\n",
       "      <td>137.824680</td>\n",
       "      <td>4.326438</td>\n",
       "      <td>7.525005</td>\n",
       "      <td>16.558581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.221860</td>\n",
       "      <td>0.292023</td>\n",
       "      <td>3.506487e+05</td>\n",
       "      <td>201.674042</td>\n",
       "      <td>0.715024</td>\n",
       "      <td>10.178012</td>\n",
       "      <td>10.228095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.980000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.810000</td>\n",
       "      <td>5.360000e+02</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>4.224000e+03</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>4.251969</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.190000</td>\n",
       "      <td>3.052450e+04</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>4.540541</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>20.885440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.899965e+06</td>\n",
       "      <td>4159.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>388.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Rating    Avg_Rating  Ratings_Count     Tok_Count  Avg_Word_Len  \\\n",
       "count  28274.000000  28274.000000   2.827400e+04  28274.000000  28118.000000   \n",
       "mean       3.835396      3.990835   8.802585e+04    137.824680      4.326438   \n",
       "std        1.221860      0.292023   3.506487e+05    201.674042      0.715024   \n",
       "min        0.000000      1.980000   0.000000e+00      1.000000      1.000000   \n",
       "25%        3.000000      3.810000   5.360000e+02     26.000000      4.000000   \n",
       "50%        4.000000      4.010000   4.224000e+03     66.000000      4.251969   \n",
       "75%        5.000000      4.190000   3.052450e+04    164.000000      4.540541   \n",
       "max        5.000000      5.000000   4.899965e+06   4159.000000     16.000000   \n",
       "\n",
       "        Sents_Count  Avg_Sent_Len  \n",
       "count  28274.000000  28274.000000  \n",
       "mean       7.525005     16.558581  \n",
       "std       10.178012     10.228095  \n",
       "min        1.000000      1.000000  \n",
       "25%        2.000000     10.750000  \n",
       "50%        4.000000     15.714286  \n",
       "75%        9.000000     20.885440  \n",
       "max      210.000000    388.000000  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f379c7d1",
   "metadata": {},
   "source": [
    "The first thing that catches my eye is token count. The mean of about 138 words seems reasonable, but STD of almost 202 words?? The quartile breakdown shows that actually most reviews are quite short, with the median being around 66 words, but it looks like an absolutely massive review at 4159 tokens is pulling up that average. I want to take a closer look at this, so I'm going to make a filter to locate specifically large token-count reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b662db95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Category</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Language</th>\n",
       "      <th>Pages</th>\n",
       "      <th>Pub_Year</th>\n",
       "      <th>Avg_Rating</th>\n",
       "      <th>Ratings_Count</th>\n",
       "      <th>Toks</th>\n",
       "      <th>Toks_Lower</th>\n",
       "      <th>Tok_Count</th>\n",
       "      <th>Avg_Word_Len</th>\n",
       "      <th>Sents</th>\n",
       "      <th>Sents_Count</th>\n",
       "      <th>Avg_Sent_Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26450</th>\n",
       "      <td>The Knight's Tale \\n Very tragic, romantic sto...</td>\n",
       "      <td>4</td>\n",
       "      <td>The Canterbury Tales</td>\n",
       "      <td>Geoffrey Chaucer</td>\n",
       "      <td>poetry</td>\n",
       "      <td>{'poetry': 1659, 'fiction': 613, 'history, his...</td>\n",
       "      <td>eng</td>\n",
       "      <td>627</td>\n",
       "      <td>1934</td>\n",
       "      <td>3.48</td>\n",
       "      <td>16</td>\n",
       "      <td>[The, Knight, 's, Tale, Very, tragic, ,, roman...</td>\n",
       "      <td>[the, knight, 's, tale, very, tragic, ,, roman...</td>\n",
       "      <td>4159</td>\n",
       "      <td>4.239285</td>\n",
       "      <td>[The Knight's Tale \\n Very tragic, romantic st...</td>\n",
       "      <td>196</td>\n",
       "      <td>21.219388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Rating  \\\n",
       "26450  The Knight's Tale \\n Very tragic, romantic sto...       4   \n",
       "\n",
       "                      Title            Author Category  \\\n",
       "26450  The Canterbury Tales  Geoffrey Chaucer   poetry   \n",
       "\n",
       "                                                  Genres Language Pages  \\\n",
       "26450  {'poetry': 1659, 'fiction': 613, 'history, his...      eng   627   \n",
       "\n",
       "      Pub_Year  Avg_Rating  Ratings_Count  \\\n",
       "26450     1934        3.48             16   \n",
       "\n",
       "                                                    Toks  \\\n",
       "26450  [The, Knight, 's, Tale, Very, tragic, ,, roman...   \n",
       "\n",
       "                                              Toks_Lower  Tok_Count  \\\n",
       "26450  [the, knight, 's, tale, very, tragic, ,, roman...       4159   \n",
       "\n",
       "       Avg_Word_Len                                              Sents  \\\n",
       "26450      4.239285  [The Knight's Tale \\n Very tragic, romantic st...   \n",
       "\n",
       "       Sents_Count  Avg_Sent_Len  \n",
       "26450          196     21.219388  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large = (total_df.Tok_Count > 4000) \n",
    "total_df[large]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465781bc",
   "metadata": {},
   "source": [
    "So there's only one review above 4000 tokens. This review should be considered a book in and of itself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8877fb91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 18)\n",
      "(221, 18)\n",
      "(1521, 18)\n"
     ]
    }
   ],
   "source": [
    "large = (total_df.Tok_Count > 3000) \n",
    "print(total_df[large].shape)\n",
    "\n",
    "large = (total_df.Tok_Count > 1000) \n",
    "print(total_df[large].shape)\n",
    "\n",
    "large = (total_df.Tok_Count > 500) \n",
    "print(total_df[large].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b7bd45",
   "metadata": {},
   "source": [
    "Considering there are over 28000 reviews total, with only 1521 being longer than 500 words, it's clear that long reviews are the outliers here. I don't think I should just exclude the long reviews, but it's definitely something to keep an eye on as it might affect some of my statistics. I was going to add TTR as a feature, but I'm going to skip that for now because I'd have to take a tiny sample of some of the longer texts to get to a comparable point to the smaller reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5b9582be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Avg_Rating</th>\n",
       "      <th>Ratings_Count</th>\n",
       "      <th>Tok_Count</th>\n",
       "      <th>Avg_Word_Len</th>\n",
       "      <th>Sents_Count</th>\n",
       "      <th>Avg_Sent_Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28274.000000</td>\n",
       "      <td>28274.000000</td>\n",
       "      <td>2.827400e+04</td>\n",
       "      <td>28274.000000</td>\n",
       "      <td>28118.000000</td>\n",
       "      <td>28274.000000</td>\n",
       "      <td>28274.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.835396</td>\n",
       "      <td>3.990835</td>\n",
       "      <td>8.802585e+04</td>\n",
       "      <td>137.824680</td>\n",
       "      <td>4.326438</td>\n",
       "      <td>7.525005</td>\n",
       "      <td>16.558581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.221860</td>\n",
       "      <td>0.292023</td>\n",
       "      <td>3.506487e+05</td>\n",
       "      <td>201.674042</td>\n",
       "      <td>0.715024</td>\n",
       "      <td>10.178012</td>\n",
       "      <td>10.228095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.980000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.810000</td>\n",
       "      <td>5.360000e+02</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>4.224000e+03</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>4.251969</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.190000</td>\n",
       "      <td>3.052450e+04</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>4.540541</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>20.885440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.899965e+06</td>\n",
       "      <td>4159.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>388.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Rating    Avg_Rating  Ratings_Count     Tok_Count  Avg_Word_Len  \\\n",
       "count  28274.000000  28274.000000   2.827400e+04  28274.000000  28118.000000   \n",
       "mean       3.835396      3.990835   8.802585e+04    137.824680      4.326438   \n",
       "std        1.221860      0.292023   3.506487e+05    201.674042      0.715024   \n",
       "min        0.000000      1.980000   0.000000e+00      1.000000      1.000000   \n",
       "25%        3.000000      3.810000   5.360000e+02     26.000000      4.000000   \n",
       "50%        4.000000      4.010000   4.224000e+03     66.000000      4.251969   \n",
       "75%        5.000000      4.190000   3.052450e+04    164.000000      4.540541   \n",
       "max        5.000000      5.000000   4.899965e+06   4159.000000     16.000000   \n",
       "\n",
       "        Sents_Count  Avg_Sent_Len  \n",
       "count  28274.000000  28274.000000  \n",
       "mean       7.525005     16.558581  \n",
       "std       10.178012     10.228095  \n",
       "min        1.000000      1.000000  \n",
       "25%        2.000000     10.750000  \n",
       "50%        4.000000     15.714286  \n",
       "75%        9.000000     20.885440  \n",
       "max      210.000000    388.000000  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61239f8d",
   "metadata": {},
   "source": [
    "Going back to this chart, let's take a quick look at the other features. Average word length of 4.33 seems pretty reasonable and close to the median of 4.25. Average sentence count looks like it falls into a similar trap to token count with some really long reviews pulling those averages up. The median is 4 sentences, and I think from here on out I'll look at median more than mean to mitigate the effect of those outliers. Average sentence length has a median of 15.71 tokens, which actually is pretty close to the mean at 16.56 tokens. That being said, the min and max are curiously short and long respectively, so I might quickly look at those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ff454889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Category</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Language</th>\n",
       "      <th>Pages</th>\n",
       "      <th>Pub_Year</th>\n",
       "      <th>Avg_Rating</th>\n",
       "      <th>Ratings_Count</th>\n",
       "      <th>Toks</th>\n",
       "      <th>Toks_Lower</th>\n",
       "      <th>Tok_Count</th>\n",
       "      <th>Avg_Word_Len</th>\n",
       "      <th>Sents</th>\n",
       "      <th>Sents_Count</th>\n",
       "      <th>Avg_Sent_Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>Xander's Panda Party</td>\n",
       "      <td>Linda Sue Park</td>\n",
       "      <td>children</td>\n",
       "      <td>{'children': 143, 'fiction': 15, 'poetry': 9, ...</td>\n",
       "      <td>eng</td>\n",
       "      <td>40</td>\n",
       "      <td>2013</td>\n",
       "      <td>4.05</td>\n",
       "      <td>1163</td>\n",
       "      <td>[O]</td>\n",
       "      <td>[o]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[O]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>3.3</td>\n",
       "      <td>3</td>\n",
       "      <td>The Miserable Mill (A Series of Unfortunate Ev...</td>\n",
       "      <td>Lemony Snicket</td>\n",
       "      <td>children</td>\n",
       "      <td>{'fiction': 1361, 'young-adult': 967, 'childre...</td>\n",
       "      <td>en-US</td>\n",
       "      <td>194</td>\n",
       "      <td>2000</td>\n",
       "      <td>3.83</td>\n",
       "      <td>103546</td>\n",
       "      <td>[3.3]</td>\n",
       "      <td>[3.3]</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[3.3]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>Cute</td>\n",
       "      <td>4</td>\n",
       "      <td>Snowmen All Year</td>\n",
       "      <td>Caralyn Buehner</td>\n",
       "      <td>children</td>\n",
       "      <td>{'children': 106, 'fiction': 3, 'fantasy, para...</td>\n",
       "      <td>eng</td>\n",
       "      <td>32</td>\n",
       "      <td>2010</td>\n",
       "      <td>3.97</td>\n",
       "      <td>715</td>\n",
       "      <td>[Cute]</td>\n",
       "      <td>[cute]</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[Cute]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Text  Rating                                              Title  \\\n",
       "0       O       0                               Xander's Panda Party   \n",
       "588   3.3       3  The Miserable Mill (A Series of Unfortunate Ev...   \n",
       "716  Cute       4                                   Snowmen All Year   \n",
       "\n",
       "              Author  Category  \\\n",
       "0     Linda Sue Park  children   \n",
       "588   Lemony Snicket  children   \n",
       "716  Caralyn Buehner  children   \n",
       "\n",
       "                                                Genres Language Pages  \\\n",
       "0    {'children': 143, 'fiction': 15, 'poetry': 9, ...      eng    40   \n",
       "588  {'fiction': 1361, 'young-adult': 967, 'childre...    en-US   194   \n",
       "716  {'children': 106, 'fiction': 3, 'fantasy, para...      eng    32   \n",
       "\n",
       "    Pub_Year  Avg_Rating  Ratings_Count    Toks Toks_Lower  Tok_Count  \\\n",
       "0       2013        4.05           1163     [O]        [o]          1   \n",
       "588     2000        3.83         103546   [3.3]      [3.3]          1   \n",
       "716     2010        3.97            715  [Cute]     [cute]          1   \n",
       "\n",
       "     Avg_Word_Len   Sents  Sents_Count  Avg_Sent_Len  \n",
       "0             1.0     [O]            1           1.0  \n",
       "588           NaN   [3.3]            1           1.0  \n",
       "716           4.0  [Cute]            1           1.0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short = (total_df.Avg_Sent_Len == 1) \n",
    "total_df[short].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f0dc694f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"first read in june 6th/2014 \\n reread in april 11th/2016 \\n I don't have words enough to say how much I love Ronan Lynch, he's my queer, angry, trashy, beautiful son and i love him so much \\n RONAN LYNCH TAKING CARE OF SMALL ANIMALS \\n RONAN LYNCH LOVING CHAINSAW \\n RONAN LYNCH LOVING HIS LITTLE BROTHER AND HIS MOM SO MUCH \\n RONAN LYNCH LAUGHING AND BEING HAPPY \\n RONAN LYNCH LOVING HIS FRIENDS AND NOT FEELING SO ALONE AFTER ALL \\n RONAN LYNCH ADMITTING TO HIMSELF HE'S GAY AND IN LOVE WITH ADAM PARRISH ISTG THIS FUCKING KID IS GOING TO KILL ME my fave *clutches chest* \\n also: matthew lynch is smol and basically the most precious human being ever \\n bluesey is THE BEST THING i'm still crying why do you make me suffer so much @ universe \\n my poor kid adam parrish is so broken in this book and i just wanna hold him and love him forever, he needs love, warm blankets, cookies and happiness \\n the women of 300 fox way are my squad goals and i love them dearly \\n i still don't really care about the gray man \\n obvs: kavinsky is the second worst piece of shit in this universe, losing only for robert parrish, and i despise his existence and i'm SO GLAD he's dead \\n and now to the best part: PYNCH, as usual, is still the best otp in my short life and i die slowly over them and i have so many emotions i just caN'T LIVE LIKE THIS oh god the 'ronan's second secret is adam parrish' KILLS ME EVERYTIME I'M SO WEAK i love pynch a lOT (pynch trash #1) \\n so, yeah, this book is gr8 and now we go to the ''maybe i dreamt you/parrish's hondayota alone time/manibus, for your hands/two gods in this church/ he realized that while he'd been looking at Ronan, Ronan had been looking at him' etc ' book or also know as blue lily lily blue and i'm excited to reread but also scared cause the raven king is so close i don't how to cope with this okay\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long = (total_df.Avg_Sent_Len == 388) \n",
    "total_df[long].Text #Find index of review\n",
    "total_df.Text.loc[15166]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7f755e",
   "metadata": {},
   "source": [
    "Okay, I see what's happening here. This reviewer made a new line for every new sentence rather than using punctuation, meaning NLTK's sentence tokenizer didn't recognize them as sentence boundaries. I'll have to look into a way around this, because I'm sure this isn't the only review where this happened. In fact, let's check. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "adfa1d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 18)\n",
      "(8, 18)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "348      ** spoiler alert ** \\n Ok so I just finished t...\n",
       "3155     wHd mn lktb ldhy m n bd't fyh, lm stT` ltwqf H...\n",
       "5951     hw rw'y@ amn bh hdh lshkhS khll Hyth mbyn lTbq...\n",
       "9579     I bought this back in'89 just after the 89 Bur...\n",
       "13773    ewlaamiiwrrnkrrmthiidiisakeruue`nge`aamaasraan...\n",
       "15166    first read in june 6th/2014 \\n reread in april...\n",
       "17212    ** spoiler alert ** \\n Setting: South Dakota: ...\n",
       "25082    My Review: 5 Stars \\n Okay so I recieved my co...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long = (total_df.Avg_Sent_Len > 300) \n",
    "print(total_df[long].shape)\n",
    "\n",
    "long = (total_df.Avg_Sent_Len > 200) \n",
    "print(total_df[long].shape)\n",
    "\n",
    "total_df[long].Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837f9ccf",
   "metadata": {},
   "source": [
    "Yeah, this is something I unfortunately noticed when saving my data samples. It seems like some reviews are just nonsense text that wasn't filtered out because it technically is English and not empty. I'm going to have to find a way to get rid of those samples or I'm sure they will end up skewing the results, but that will be a problem for my next progress report.\n",
    "\n",
    "**UPDATE FROM PROGRESS REPORT 3 - FILTERING OUT NONSENSE TEXT**\n",
    "\n",
    "I found this Python library, nostril, that is able to differentiate between text that is real and text that is most likely nonsensical, so I tried it out to see if it could solve my problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "21f8dcfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from nostril import nonsense\n",
    "\n",
    "nonsense_test = [\"This is a real sentence.\", \"i luv 2 read bookz\", \"ghsuofdisogjifs\"]\n",
    "\n",
    "for sent in nonsense_test:\n",
    "    print(nonsense(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd869f5",
   "metadata": {},
   "source": [
    "It seems to do a decent job, even with more slang and misspellings. That being said, input shorter than 6 characters can't be categorized, but I don't want the process to stop when it throws an error for a text that is too short. I made the function below to catch those exceptions, using this to map whether each review in the dataframe below is real or nonsense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c564215a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'short'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_nonsense(text):\n",
    "    try:\n",
    "        if nonsense(text) == True:\n",
    "            return \"nonsense\"\n",
    "        if nonsense(text) == False:\n",
    "            return \"real\"\n",
    "    except ValueError as error:\n",
    "        return \"short\"\n",
    "\n",
    "test_nonsense(\"this\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0e6d2bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j9/9lmff3zj6bxgfpsb8gm8pjrw0000gn/T/ipykernel_37260/3056095903.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[\"Nonsense\"] = test_df.Text.map(test_nonsense)\n"
     ]
    }
   ],
   "source": [
    "test_df = total_df.head()\n",
    "test_df[\"Nonsense\"] = test_df.Text.map(test_nonsense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "827150e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Category</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Language</th>\n",
       "      <th>Pages</th>\n",
       "      <th>Pub_Year</th>\n",
       "      <th>Avg_Rating</th>\n",
       "      <th>Ratings_Count</th>\n",
       "      <th>Toks</th>\n",
       "      <th>Toks_Lower</th>\n",
       "      <th>Tok_Count</th>\n",
       "      <th>Avg_Word_Len</th>\n",
       "      <th>Sents</th>\n",
       "      <th>Sents_Count</th>\n",
       "      <th>Avg_Sent_Len</th>\n",
       "      <th>Nonsense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>Xander's Panda Party</td>\n",
       "      <td>Linda Sue Park</td>\n",
       "      <td>children</td>\n",
       "      <td>{'children': 143, 'fiction': 15, 'poetry': 9, ...</td>\n",
       "      <td>eng</td>\n",
       "      <td>40</td>\n",
       "      <td>2013</td>\n",
       "      <td>4.05</td>\n",
       "      <td>1163</td>\n",
       "      <td>[O]</td>\n",
       "      <td>[o]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[O]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my pick for the caldecott so far...</td>\n",
       "      <td>5</td>\n",
       "      <td>Xander's Panda Party</td>\n",
       "      <td>Linda Sue Park</td>\n",
       "      <td>children</td>\n",
       "      <td>{'children': 143, 'fiction': 15, 'poetry': 9, ...</td>\n",
       "      <td>eng</td>\n",
       "      <td>40</td>\n",
       "      <td>2013</td>\n",
       "      <td>4.05</td>\n",
       "      <td>1163</td>\n",
       "      <td>[my, pick, for, the, caldecott, so, far, ...]</td>\n",
       "      <td>[my, pick, for, the, caldecott, so, far, ...]</td>\n",
       "      <td>8</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>[my pick for the caldecott so far...]</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This time Dan and Amy go to the Bahamas and Ja...</td>\n",
       "      <td>4</td>\n",
       "      <td>Storm Warning (The 39 Clues, #9)</td>\n",
       "      <td>Linda Sue Park</td>\n",
       "      <td>children</td>\n",
       "      <td>{'mystery, thriller, crime': 188, 'young-adult...</td>\n",
       "      <td>eng</td>\n",
       "      <td>190</td>\n",
       "      <td>2010</td>\n",
       "      <td>3.98</td>\n",
       "      <td>39904</td>\n",
       "      <td>[This, time, Dan, and, Amy, go, to, the, Baham...</td>\n",
       "      <td>[this, time, dan, and, amy, go, to, the, baham...</td>\n",
       "      <td>35</td>\n",
       "      <td>4.176471</td>\n",
       "      <td>[This time Dan and Amy go to the Bahamas and J...</td>\n",
       "      <td>2</td>\n",
       "      <td>17.5</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Loved the excerpts where Julia, the main chara...</td>\n",
       "      <td>5</td>\n",
       "      <td>Project Mulberry</td>\n",
       "      <td>Linda Sue Park</td>\n",
       "      <td>children</td>\n",
       "      <td>{'fiction': 122, 'children': 111, 'young-adult...</td>\n",
       "      <td>eng</td>\n",
       "      <td>240</td>\n",
       "      <td>2007</td>\n",
       "      <td>3.67</td>\n",
       "      <td>2929</td>\n",
       "      <td>[Loved, the, excerpts, where, Julia, ,, the, m...</td>\n",
       "      <td>[loved, the, excerpts, where, julia, ,, the, m...</td>\n",
       "      <td>18</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>[Loved the excerpts where Julia, the main char...</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I liked the illustrations, which are are - wel...</td>\n",
       "      <td>4</td>\n",
       "      <td>A Moon of My Own</td>\n",
       "      <td>Jennifer Rustgi</td>\n",
       "      <td>children</td>\n",
       "      <td>{'children': 13, 'young-adult': 2, 'non-fictio...</td>\n",
       "      <td>eng</td>\n",
       "      <td>32</td>\n",
       "      <td>2016</td>\n",
       "      <td>3.78</td>\n",
       "      <td>84</td>\n",
       "      <td>[I, liked, the, illustrations, ,, which, are, ...</td>\n",
       "      <td>[i, liked, the, illustrations, ,, which, are, ...</td>\n",
       "      <td>153</td>\n",
       "      <td>4.484375</td>\n",
       "      <td>[I liked the illustrations, which are are - we...</td>\n",
       "      <td>5</td>\n",
       "      <td>30.6</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Rating  \\\n",
       "0                                                  O       0   \n",
       "1                my pick for the caldecott so far...       5   \n",
       "2  This time Dan and Amy go to the Bahamas and Ja...       4   \n",
       "3  Loved the excerpts where Julia, the main chara...       5   \n",
       "4  I liked the illustrations, which are are - wel...       4   \n",
       "\n",
       "                              Title           Author  Category  \\\n",
       "0              Xander's Panda Party   Linda Sue Park  children   \n",
       "1              Xander's Panda Party   Linda Sue Park  children   \n",
       "2  Storm Warning (The 39 Clues, #9)   Linda Sue Park  children   \n",
       "3                  Project Mulberry   Linda Sue Park  children   \n",
       "4                  A Moon of My Own  Jennifer Rustgi  children   \n",
       "\n",
       "                                              Genres Language Pages Pub_Year  \\\n",
       "0  {'children': 143, 'fiction': 15, 'poetry': 9, ...      eng    40     2013   \n",
       "1  {'children': 143, 'fiction': 15, 'poetry': 9, ...      eng    40     2013   \n",
       "2  {'mystery, thriller, crime': 188, 'young-adult...      eng   190     2010   \n",
       "3  {'fiction': 122, 'children': 111, 'young-adult...      eng   240     2007   \n",
       "4  {'children': 13, 'young-adult': 2, 'non-fictio...      eng    32     2016   \n",
       "\n",
       "   Avg_Rating  Ratings_Count  \\\n",
       "0        4.05           1163   \n",
       "1        4.05           1163   \n",
       "2        3.98          39904   \n",
       "3        3.67           2929   \n",
       "4        3.78             84   \n",
       "\n",
       "                                                Toks  \\\n",
       "0                                                [O]   \n",
       "1      [my, pick, for, the, caldecott, so, far, ...]   \n",
       "2  [This, time, Dan, and, Amy, go, to, the, Baham...   \n",
       "3  [Loved, the, excerpts, where, Julia, ,, the, m...   \n",
       "4  [I, liked, the, illustrations, ,, which, are, ...   \n",
       "\n",
       "                                          Toks_Lower  Tok_Count  Avg_Word_Len  \\\n",
       "0                                                [o]          1      1.000000   \n",
       "1      [my, pick, for, the, caldecott, so, far, ...]          8      3.714286   \n",
       "2  [this, time, dan, and, amy, go, to, the, baham...         35      4.176471   \n",
       "3  [loved, the, excerpts, where, julia, ,, the, m...         18      5.000000   \n",
       "4  [i, liked, the, illustrations, ,, which, are, ...        153      4.484375   \n",
       "\n",
       "                                               Sents  Sents_Count  \\\n",
       "0                                                [O]            1   \n",
       "1              [my pick for the caldecott so far...]            1   \n",
       "2  [This time Dan and Amy go to the Bahamas and J...            2   \n",
       "3  [Loved the excerpts where Julia, the main char...            1   \n",
       "4  [I liked the illustrations, which are are - we...            5   \n",
       "\n",
       "   Avg_Sent_Len Nonsense  \n",
       "0           1.0    short  \n",
       "1           8.0     real  \n",
       "2          17.5     real  \n",
       "3          18.0     real  \n",
       "4          30.6     real  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b84695",
   "metadata": {},
   "source": [
    "Seems to work on a small subset, so let's try the whole thing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a269e838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "real        27219\n",
       "nonsense      635\n",
       "short         420\n",
       "Name: Nonsense, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df[\"Nonsense\"] = total_df.Text.map(test_nonsense)\n",
    "total_df.Nonsense.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbc1ac2",
   "metadata": {},
   "source": [
    "635 out of over 27000 reviews isn't a ton (only about 2%), so that's not terrible. Let's take a look at some of these nonsense reviews just to make sure they're classified correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2229e975",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Category</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Language</th>\n",
       "      <th>Pages</th>\n",
       "      <th>Pub_Year</th>\n",
       "      <th>Avg_Rating</th>\n",
       "      <th>Ratings_Count</th>\n",
       "      <th>Toks</th>\n",
       "      <th>Toks_Lower</th>\n",
       "      <th>Tok_Count</th>\n",
       "      <th>Avg_Word_Len</th>\n",
       "      <th>Sents</th>\n",
       "      <th>Sents_Count</th>\n",
       "      <th>Avg_Sent_Len</th>\n",
       "      <th>Nonsense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>For my Goodreads friends, yes, I read a childr...</td>\n",
       "      <td>3</td>\n",
       "      <td>The Twits</td>\n",
       "      <td>Roald Dahl</td>\n",
       "      <td>children</td>\n",
       "      <td>{'children': 447, 'fiction': 173, 'young-adult...</td>\n",
       "      <td>eng</td>\n",
       "      <td>96</td>\n",
       "      <td>2004</td>\n",
       "      <td>3.94</td>\n",
       "      <td>83762</td>\n",
       "      <td>[For, my, Goodreads, friends, ,, yes, ,, I, re...</td>\n",
       "      <td>[for, my, goodreads, friends, ,, yes, ,, i, re...</td>\n",
       "      <td>365</td>\n",
       "      <td>4.068182</td>\n",
       "      <td>[For my Goodreads friends, yes, I read a child...</td>\n",
       "      <td>15</td>\n",
       "      <td>24.333333</td>\n",
       "      <td>nonsense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Everything I want a book to be. AMAAAAZZZING!!...</td>\n",
       "      <td>5</td>\n",
       "      <td>Anne of Green Gables (Anne of Green Gables, #1)</td>\n",
       "      <td>L.M. Montgomery</td>\n",
       "      <td>children</td>\n",
       "      <td>{'fiction': 5772, 'young-adult': 3267, 'childr...</td>\n",
       "      <td>eng</td>\n",
       "      <td></td>\n",
       "      <td>2003</td>\n",
       "      <td>4.23</td>\n",
       "      <td>513174</td>\n",
       "      <td>[Everything, I, want, a, book, to, be, ., AMAA...</td>\n",
       "      <td>[everything, i, want, a, book, to, be, ., amaa...</td>\n",
       "      <td>31</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>[Everything I want a book to be., AMAAAAZZZING...</td>\n",
       "      <td>3</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>nonsense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>It's no Miraculous Journey of Edward Tulane, b...</td>\n",
       "      <td>3</td>\n",
       "      <td>Raymie Nightingale</td>\n",
       "      <td>Kate DiCamillo</td>\n",
       "      <td>children</td>\n",
       "      <td>{'fiction': 718, 'history, historical fiction,...</td>\n",
       "      <td>eng</td>\n",
       "      <td>272</td>\n",
       "      <td>2016</td>\n",
       "      <td>3.92</td>\n",
       "      <td>9146</td>\n",
       "      <td>[It, 's, no, Miraculous, Journey, of, Edward, ...</td>\n",
       "      <td>[it, 's, no, miraculous, journey, of, edward, ...</td>\n",
       "      <td>481</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>[It's no Miraculous Journey of Edward Tulane, ...</td>\n",
       "      <td>36</td>\n",
       "      <td>13.361111</td>\n",
       "      <td>nonsense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>sypvrv shl hklb bq, shnkhtp mmshpkhh qlypvrnyt...</td>\n",
       "      <td>4</td>\n",
       "      <td>The Call of the Wild</td>\n",
       "      <td>Jack London</td>\n",
       "      <td>children</td>\n",
       "      <td>{'young-adult': 696, 'fiction': 905, 'history,...</td>\n",
       "      <td>eng</td>\n",
       "      <td>150</td>\n",
       "      <td>2012</td>\n",
       "      <td>3.83</td>\n",
       "      <td>4900</td>\n",
       "      <td>[sypvrv, shl, hklb, bq, ,, shnkhtp, mmshpkhh, ...</td>\n",
       "      <td>[sypvrv, shl, hklb, bq, ,, shnkhtp, mmshpkhh, ...</td>\n",
       "      <td>123</td>\n",
       "      <td>4.715596</td>\n",
       "      <td>[sypvrv shl hklb bq, shnkhtp mmshpkhh qlypvrny...</td>\n",
       "      <td>7</td>\n",
       "      <td>17.571429</td>\n",
       "      <td>nonsense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>hdh lktb mn lklsykyt ldhy lTlm 'rdt bty`h w ns...</td>\n",
       "      <td>5</td>\n",
       "      <td>The Giving Tree</td>\n",
       "      <td>Shel Silverstein</td>\n",
       "      <td>children</td>\n",
       "      <td>{'children': 13199, 'fiction': 2045, 'poetry':...</td>\n",
       "      <td>eng</td>\n",
       "      <td>64</td>\n",
       "      <td>1964</td>\n",
       "      <td>4.37</td>\n",
       "      <td>720582</td>\n",
       "      <td>[hdh, lktb, mn, lklsykyt, ldhy, lTlm, 'rdt, bt...</td>\n",
       "      <td>[hdh, lktb, mn, lklsykyt, ldhy, ltlm, 'rdt, bt...</td>\n",
       "      <td>25</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>[hdh lktb mn lklsykyt ldhy lTlm 'rdt bty`h w n...</td>\n",
       "      <td>3</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>nonsense</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text  Rating  \\\n",
       "69   For my Goodreads friends, yes, I read a childr...       3   \n",
       "140  Everything I want a book to be. AMAAAAZZZING!!...       5   \n",
       "221  It's no Miraculous Journey of Edward Tulane, b...       3   \n",
       "268  sypvrv shl hklb bq, shnkhtp mmshpkhh qlypvrnyt...       4   \n",
       "293  hdh lktb mn lklsykyt ldhy lTlm 'rdt bty`h w ns...       5   \n",
       "\n",
       "                                               Title            Author  \\\n",
       "69                                         The Twits        Roald Dahl   \n",
       "140  Anne of Green Gables (Anne of Green Gables, #1)   L.M. Montgomery   \n",
       "221                               Raymie Nightingale    Kate DiCamillo   \n",
       "268                             The Call of the Wild       Jack London   \n",
       "293                                  The Giving Tree  Shel Silverstein   \n",
       "\n",
       "     Category                                             Genres Language  \\\n",
       "69   children  {'children': 447, 'fiction': 173, 'young-adult...      eng   \n",
       "140  children  {'fiction': 5772, 'young-adult': 3267, 'childr...      eng   \n",
       "221  children  {'fiction': 718, 'history, historical fiction,...      eng   \n",
       "268  children  {'young-adult': 696, 'fiction': 905, 'history,...      eng   \n",
       "293  children  {'children': 13199, 'fiction': 2045, 'poetry':...      eng   \n",
       "\n",
       "    Pages Pub_Year  Avg_Rating  Ratings_Count  \\\n",
       "69     96     2004        3.94          83762   \n",
       "140           2003        4.23         513174   \n",
       "221   272     2016        3.92           9146   \n",
       "268   150     2012        3.83           4900   \n",
       "293    64     1964        4.37         720582   \n",
       "\n",
       "                                                  Toks  \\\n",
       "69   [For, my, Goodreads, friends, ,, yes, ,, I, re...   \n",
       "140  [Everything, I, want, a, book, to, be, ., AMAA...   \n",
       "221  [It, 's, no, Miraculous, Journey, of, Edward, ...   \n",
       "268  [sypvrv, shl, hklb, bq, ,, shnkhtp, mmshpkhh, ...   \n",
       "293  [hdh, lktb, mn, lklsykyt, ldhy, lTlm, 'rdt, bt...   \n",
       "\n",
       "                                            Toks_Lower  Tok_Count  \\\n",
       "69   [for, my, goodreads, friends, ,, yes, ,, i, re...        365   \n",
       "140  [everything, i, want, a, book, to, be, ., amaa...         31   \n",
       "221  [it, 's, no, miraculous, journey, of, edward, ...        481   \n",
       "268  [sypvrv, shl, hklb, bq, ,, shnkhtp, mmshpkhh, ...        123   \n",
       "293  [hdh, lktb, mn, lklsykyt, ldhy, ltlm, 'rdt, bt...         25   \n",
       "\n",
       "     Avg_Word_Len                                              Sents  \\\n",
       "69       4.068182  [For my Goodreads friends, yes, I read a child...   \n",
       "140      4.500000  [Everything I want a book to be., AMAAAAZZZING...   \n",
       "221      4.200000  [It's no Miraculous Journey of Edward Tulane, ...   \n",
       "268      4.715596  [sypvrv shl hklb bq, shnkhtp mmshpkhh qlypvrny...   \n",
       "293      3.250000  [hdh lktb mn lklsykyt ldhy lTlm 'rdt bty`h w n...   \n",
       "\n",
       "     Sents_Count  Avg_Sent_Len  Nonsense  \n",
       "69            15     24.333333  nonsense  \n",
       "140            3     10.333333  nonsense  \n",
       "221           36     13.361111  nonsense  \n",
       "268            7     17.571429  nonsense  \n",
       "293            3      8.333333  nonsense  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonsense_filter = (total_df.Nonsense == \"nonsense\")\n",
    "total_df[nonsense_filter].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2efc2d1",
   "metadata": {},
   "source": [
    "Unfortunately some of these look like real reviews even though they were tagged as nonsense. I converted the full nonsense dataframe into a CSV so I could quickly look over the full text of all the reviews, and unfortunately, while it did find some nonsense text, many of the reviews were still real. Therefore I will not be removing all the reviews tagged as nonsense because I would be getting rid of valid input, and the real nonsense reviews make up a very small portion of the data. However, this should be noted as a limitation of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3096c887",
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_df[nonsense_filter].to_csv('/Users/ashleyfeiler/Documents/data_science/Goodreads-Genre-Reviews-Analysis/data/nonsense_reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99c7a28",
   "metadata": {},
   "source": [
    "Anyway, there's one last feature I still want to add - sentiment! I'm not too familiar with NLTK's sentiment analyzer, so I'm going to create some test cases first just to get a feel for how it works.\n",
    "\n",
    "### Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f83aa414",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I loved this book!!!\n",
      "{'neg': 0.0, 'neu': 0.295, 'pos': 0.705, 'compound': 0.6981}\n",
      "positive\n",
      "5\n",
      "\n",
      "Boring.\n",
      "{'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound': -0.3182}\n",
      "negative\n",
      "2\n",
      "\n",
      "This book was ok - not my favorite, but not the worst\n",
      "{'neg': 0.11, 'neu': 0.507, 'pos': 0.383, 'compound': 0.6487}\n",
      "positive\n",
      "5\n",
      "\n",
      "My heart after reading this book: :) <3\n",
      "{'neg': 0.0, 'neu': 0.504, 'pos': 0.496, 'compound': 0.7096}\n",
      "positive\n",
      "5\n",
      "\n",
      "Literally the worst book I've ever read\n",
      "{'neg': 0.406, 'neu': 0.594, 'pos': 0.0, 'compound': -0.6249}\n",
      "negative\n",
      "1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#nltk.download('vader_lexicon')\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "sentiment = SentimentIntensityAnalyzer()\n",
    "\n",
    "test_sents = [\"I loved this book!!!\", \n",
    "             \"Boring.\", \n",
    "             \"This book was ok - not my favorite, but not the worst\",\n",
    "             \"My heart after reading this book: :) <3\",\n",
    "             \"Literally the worst book I've ever read\"]\n",
    "\n",
    "for sent in test_sents:\n",
    "    print(sent)\n",
    "    print(sentiment.polarity_scores(sent))\n",
    "    compound = sentiment.polarity_scores(sent)['compound']\n",
    "    if compound > 0:\n",
    "        print('positive')\n",
    "    elif compound < 0:\n",
    "        print('negative')\n",
    "    elif compound == 0:\n",
    "        print('neutral')\n",
    "        \n",
    "    if compound >= -1 and compound < -0.6:\n",
    "        print('1\\n')\n",
    "    elif compound >= -0.6 and compound < -0.2:\n",
    "        print('2\\n')\n",
    "    elif compound >= -0.2 and compound < 0.2:\n",
    "        print('3\\n')\n",
    "    elif compound >= 0.2 and compound < 0.6:\n",
    "        print('4\\n')\n",
    "    elif compound >= 0.6:\n",
    "        print('5\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3a836d",
   "metadata": {},
   "source": [
    "Trying to get this sentiment score to correspond with stars (1-5) doesn't seem to work that well (some of the reviews it scored as 5 are definitely not that enthusiastic), so for right now I'll just stick with the overall positive/negative tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7120a68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j9/9lmff3zj6bxgfpsb8gm8pjrw0000gn/T/ipykernel_37260/306129234.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['Sentiment_Num'] = test_df.Sents.map(sent_analysis)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.00000\n",
       "1    0.00000\n",
       "2    0.15910\n",
       "3    0.59940\n",
       "4    0.44342\n",
       "Name: Sentiment_Num, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sent_analysis(sents):\n",
    "    scores = [sentiment.polarity_scores(sent)['compound'] for sent in sents]\n",
    "    average = np.mean(scores)\n",
    "    return average\n",
    "\n",
    "test_df['Sentiment_Num'] = test_df.Sents.map(sent_analysis)\n",
    "test_df.Sentiment_Num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d3645793",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df['Sentiment_Num'] = total_df.Sents.map(sent_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4b340057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment.polarity_scores(test_df.Text.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c8ac345c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j9/9lmff3zj6bxgfpsb8gm8pjrw0000gn/T/ipykernel_37260/751213680.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['Sentiment_Tag'] = test_df.Sentiment_Num.map(tag_sentiment)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     neutral\n",
       "1     neutral\n",
       "2    positive\n",
       "3    positive\n",
       "4    positive\n",
       "Name: Sentiment_Tag, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tag_sentiment(score):\n",
    "    if score > 0:\n",
    "        tag = 'positive'\n",
    "    elif score < 0:\n",
    "        tag = 'negative'\n",
    "    else:\n",
    "        tag = 'neutral'\n",
    "    \n",
    "    return tag\n",
    "\n",
    "test_df['Sentiment_Tag'] = test_df.Sentiment_Num.map(tag_sentiment)\n",
    "test_df.Sentiment_Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5ede0828",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df['Sentiment_Tag'] = total_df.Sentiment_Num.map(tag_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "00f0a393",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Avg_Rating</th>\n",
       "      <th>Ratings_Count</th>\n",
       "      <th>Tok_Count</th>\n",
       "      <th>Avg_Word_Len</th>\n",
       "      <th>Sents_Count</th>\n",
       "      <th>Avg_Sent_Len</th>\n",
       "      <th>Sentiment_Num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28274.000000</td>\n",
       "      <td>28274.000000</td>\n",
       "      <td>2.827400e+04</td>\n",
       "      <td>28274.000000</td>\n",
       "      <td>28118.000000</td>\n",
       "      <td>28274.000000</td>\n",
       "      <td>28274.000000</td>\n",
       "      <td>28274.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.835396</td>\n",
       "      <td>3.990835</td>\n",
       "      <td>8.802585e+04</td>\n",
       "      <td>137.824680</td>\n",
       "      <td>4.326438</td>\n",
       "      <td>7.525005</td>\n",
       "      <td>16.558581</td>\n",
       "      <td>0.234953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.221860</td>\n",
       "      <td>0.292023</td>\n",
       "      <td>3.506487e+05</td>\n",
       "      <td>201.674042</td>\n",
       "      <td>0.715024</td>\n",
       "      <td>10.178012</td>\n",
       "      <td>10.228095</td>\n",
       "      <td>0.272964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.980000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.949300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.810000</td>\n",
       "      <td>5.360000e+02</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.750000</td>\n",
       "      <td>0.038188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>4.224000e+03</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>4.251969</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.714286</td>\n",
       "      <td>0.229155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.190000</td>\n",
       "      <td>3.052450e+04</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>4.540541</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>20.885440</td>\n",
       "      <td>0.417267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.899965e+06</td>\n",
       "      <td>4159.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>388.000000</td>\n",
       "      <td>0.990300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Rating    Avg_Rating  Ratings_Count     Tok_Count  Avg_Word_Len  \\\n",
       "count  28274.000000  28274.000000   2.827400e+04  28274.000000  28118.000000   \n",
       "mean       3.835396      3.990835   8.802585e+04    137.824680      4.326438   \n",
       "std        1.221860      0.292023   3.506487e+05    201.674042      0.715024   \n",
       "min        0.000000      1.980000   0.000000e+00      1.000000      1.000000   \n",
       "25%        3.000000      3.810000   5.360000e+02     26.000000      4.000000   \n",
       "50%        4.000000      4.010000   4.224000e+03     66.000000      4.251969   \n",
       "75%        5.000000      4.190000   3.052450e+04    164.000000      4.540541   \n",
       "max        5.000000      5.000000   4.899965e+06   4159.000000     16.000000   \n",
       "\n",
       "        Sents_Count  Avg_Sent_Len  Sentiment_Num  \n",
       "count  28274.000000  28274.000000   28274.000000  \n",
       "mean       7.525005     16.558581       0.234953  \n",
       "std       10.178012     10.228095       0.272964  \n",
       "min        1.000000      1.000000      -0.949300  \n",
       "25%        2.000000     10.750000       0.038188  \n",
       "50%        4.000000     15.714286       0.229155  \n",
       "75%        9.000000     20.885440       0.417267  \n",
       "max      210.000000    388.000000       0.990300  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabb693f",
   "metadata": {},
   "source": [
    "I'm extremely curious to know what the most negative and most positive reviews were, so let's look!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7acb7056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 21)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg = (total_df.Sentiment_Num < -0.9) \n",
    "total_df[neg].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "36db854e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This book was too encyclopedic for me, with description of murder after murder and little-to-no narrative structure other than the sequential murders.\n",
      "Slow starting but once into its stride 19 Purchase Street is a hearty tale of money laundering, greed, revenge murder and a billion dollar robbery caper.\n"
     ]
    }
   ],
   "source": [
    "print(total_df[neg].Text.iloc[0])\n",
    "print(total_df[neg].Text.iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fa520d",
   "metadata": {},
   "source": [
    "Ok, so the first one is pretty accurate, but with the second one, it looks like the sentiment analyzer saw all those words like \"greed\", \"revenge\", and \"murder\" and rated the review as negative, even though the review itself seems to overall like the book. Not sure there's much I can do about this, but it's something to keep in mind.\n",
    "\n",
    "Let's look at the positive!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "93bd31d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 21)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = (total_df.Sentiment_Num > 0.95) \n",
    "total_df[pos].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4207b7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love frozen because... \n",
      " Olaf = Cute, Fuuny, Sweet \n",
      " Elsa = Fearless and Loving \n",
      " Anna = Caring and Brave\n",
      "Brilliant writing, fascinating history, but the novel bogs down a bit about 2/3 through....still a wonderfully good read if not a page-turner.\n"
     ]
    }
   ],
   "source": [
    "print(total_df[pos].Text.iloc[3])\n",
    "print(total_df[pos].Text.iloc[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55476e31",
   "metadata": {},
   "source": [
    "Once again, the first example seems pretty spot on, but as a human reader, I can tell the second review has a little bit of hesitation and probably shouldn't be at a 0.95 if 1.0 means the most positive a text could be. But for what I have to work with, I think this will be a good tool, especially given that it understands differences like slang terms, emoticons, and differences in tone conveyed through things like all caps. It'll be really interesting to see how sentiment derived from the review text compares to the rating people gave the book.\n",
    "\n",
    "### Part of Speech\n",
    "\n",
    "Time for the last thing I want to try: POS tagging! I feel like the adjectives used for each different genre's review could have a wide semantic range, so I'm going to use NLTK's POS tagger to provide that information. (I wanted to use Spacy but was having some trouble downloading it - if I'm able to get that figured out, I'll probably come back and use that instead)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "31c5784a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy --user\n",
    "#!python -m spacy download \"en_core_web_sm\" --user\n",
    "#import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9d643f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'rather', 'enjoyed', 'the', 'book', 'more', 'than', 'the', 'movie', '.', 'A', 'lot', 'of', 'detail', 'was', 'lost', 'in', 'the', 'movie', '.', 'And', 'I', 'feel', 'some', 'important', 'insights', 'that', 'I', 'feel', 'developed', 'the', 'storyline', 'better', 'and', 'assisted', 'with', 'much', 'more', 'understanding', 'of', 'Jonas', \"'\", 'character', 'were', 'not', 'introduced', 'in', 'the', 'movie', '.', 'Both', 'are', 'good', ';', 'however', ',', 'I', 'recommend', 'the', 'book']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "test_text = nltk.word_tokenize(total_df.Text.iloc[10])\n",
    "test_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3c4be9",
   "metadata": {},
   "source": [
    "I only really am interested in adjectives, so I'm going to make a function that can be used to map a list of all adjectives used in a review to a new column in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7977a1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('more', 'JJR'), ('important', 'JJ'), ('understanding', 'JJ'), ('good', 'JJ')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_adjs(toks):\n",
    "    adj_list = []\n",
    "    pos_list = nltk.pos_tag(toks)\n",
    "    for (tok, pos) in pos_list:\n",
    "        if pos.startswith('JJ'):\n",
    "            adj_list.append((tok, pos))\n",
    "    \n",
    "    return adj_list\n",
    "\n",
    "find_adjs(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e31fe865",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                   []\n",
      "1                                                   []\n",
      "2                                         [(next, JJ)]\n",
      "3                                         [(main, JJ)]\n",
      "4    [(luminous, JJ), (more, JJR), (mundane, JJ), (...\n",
      "Name: Adjs, dtype: object\n",
      "[('luminous', 'JJ'), ('more', 'JJR'), ('mundane', 'JJ'), ('trite', 'JJ'), ('poetic', 'JJ'), ('back', 'JJ'), ('useful', 'JJ'), ('informative', 'JJ'), ('full', 'JJ'), ('unlikely', 'JJ')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j9/9lmff3zj6bxgfpsb8gm8pjrw0000gn/T/ipykernel_37260/4040758494.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['Adjs'] = test_df.Toks.map(find_adjs)\n"
     ]
    }
   ],
   "source": [
    "test_df['Adjs'] = test_df.Toks.map(find_adjs)\n",
    "print(test_df.Adjs)\n",
    "print(test_df.Adjs.iloc[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d988f5e",
   "metadata": {},
   "source": [
    "Works on a small subset, just returning an empty list for no adjectives, which is good to keep in mind if I end up wanting to filter those out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c97e306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df['Adjs'] = total_df.Toks.map(find_adjs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e65ea755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    28274.000000\n",
       "mean         9.872073\n",
       "std         14.076462\n",
       "min          0.000000\n",
       "25%          2.000000\n",
       "50%          5.000000\n",
       "75%         12.000000\n",
       "max        290.000000\n",
       "Name: Adjs_Count, dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df['Adjs_Count'] = total_df.Adjs.map(len)\n",
    "total_df.Adjs_Count.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968f5881",
   "metadata": {},
   "source": [
    "As with sentence length, there seem to be pretty significant high-count outliers, so when looking at descriptive statistics like these, I'm going to pay more attention to the median (50%) than the mean. \n",
    "\n",
    "Now that my dataframe has all the info I want, I'm going to pickle this file and complete the analysis in a separate Jupyter Notebook to keep things clean. Check out my Data Analysis JNB for more info!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "42ac2f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = open('data/analysis_df.pkl', 'wb')\n",
    "#pickle.dump(total_df, f)\n",
    "#f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
