{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69233e18",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "Ashley Feiler, aef56@pitt.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5ee665",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a291f254",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7853563f",
   "metadata": {},
   "source": [
    "## Sharable Data Samples\n",
    "Because I can't share all of the data I'm using due to licensing, I plan on sharing samples. Since my computer could only handle loading so much data at a time, I used separate Jupyter Notebooks for different genres that I could open, merge the necessary data, pickle a smaller sample file, and then close, freeing memory. In this file, I will unpickle and combine all of those samples to then share."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4288a9b",
   "metadata": {},
   "source": [
    "### Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77832869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/ashleyfeiler/Documents/data_science/Goodreads-Genre-Reviews-Analysis/data/genre_share/fantasy_share.pkl'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = '/Users/ashleyfeiler/Documents/data_science/Goodreads-Genre-Reviews-Analysis/data/'\n",
    "\n",
    "share_files = glob.glob(directory + 'genre_share/*.pkl') #Get filepath of all pickled files\n",
    "print(len(share_files)) #Confirm 8 files for 8 genres\n",
    "share_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db42eecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 40 entries, 0 to 4\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   user_id       40 non-null     object\n",
      " 1   book_id       40 non-null     int64 \n",
      " 2   review_id     40 non-null     object\n",
      " 3   rating        40 non-null     int64 \n",
      " 4   review_text   40 non-null     object\n",
      " 5   date_added    40 non-null     object\n",
      " 6   date_updated  40 non-null     object\n",
      " 7   read_at       40 non-null     object\n",
      " 8   started_at    40 non-null     object\n",
      " 9   n_votes       40 non-null     int64 \n",
      " 10  n_comments    40 non-null     int64 \n",
      "dtypes: int64(4), object(7)\n",
      "memory usage: 3.8+ KB\n"
     ]
    }
   ],
   "source": [
    "share_df = pd.DataFrame() #Create empty DataFrame to append each genre's sample to\n",
    "\n",
    "for pkl in share_files: #For each file directory, load file and add to shared DataFrame\n",
    "    f = open(pkl, 'rb')  \n",
    "    df = pickle.load(f)     \n",
    "    f.close()  \n",
    "    share_df = pd.concat([share_df, df])\n",
    "    \n",
    "share_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788102b7",
   "metadata": {},
   "source": [
    "This confirms that all together, there are 40 review samples just like there were supposed to be (5 from 8 genres). To keep the sample as minimal as possible to stay within Fair Use guidelines, I will take a sample of only 5 of these 40 reviews to then save as a CSV and share in my public repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4253e2aa",
   "metadata": {},
   "source": [
    "(The code below that writes the CSV file has been commented out to prevent the CSV file from being overwritten every time this notebook is run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6bae7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#genre_samples = share_df.sample(5)\n",
    "#genre_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5f539c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#genre_samples.to_csv('data_samples/Genre_Samples.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a607d3a0",
   "metadata": {},
   "source": [
    "### Condensed Data\n",
    "That first process was to show a sample of what the original UCSD data looked like, but I also want to show the final format of data that I compiled and will be working with for my analysis. Below is the same process as above, but with the final DataFrames I created for each genre (each genre ranging from around 3000-4000 reviews). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01acbbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/ashleyfeiler/Documents/data_science/Goodreads-Genre-Reviews-Analysis/data/genre_pkls/children_short.pkl'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_files = glob.glob(directory + 'genre_pkls/*.pkl')\n",
    "print(len(genre_files))\n",
    "genre_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06c0397f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 28274 entries, 0 to 4998\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Text           28274 non-null  object \n",
      " 1   Rating         28274 non-null  int64  \n",
      " 2   Title          28274 non-null  object \n",
      " 3   Author         28274 non-null  object \n",
      " 4   Category       28274 non-null  object \n",
      " 5   Genres         28274 non-null  object \n",
      " 6   Language       28274 non-null  object \n",
      " 7   Pages          28274 non-null  object \n",
      " 8   Pub_Year       28274 non-null  object \n",
      " 9   Avg_Rating     28274 non-null  float64\n",
      " 10  Ratings_Count  28274 non-null  int64  \n",
      " 11  User_ID        28274 non-null  object \n",
      "dtypes: float64(1), int64(2), object(9)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "total_df = pd.DataFrame()\n",
    "\n",
    "for pkl in genre_files:\n",
    "    f = open(pkl, 'rb')  \n",
    "    df = pickle.load(f)     \n",
    "    f.close()  \n",
    "    total_df = pd.concat([total_df, df])\n",
    "    \n",
    "total_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501d2cc1",
   "metadata": {},
   "source": [
    "Combining the samples from all 8 genres resulted in a total of 28274 reviews in total, which is a pretty decent amount of data to work with! Further down I will get into some more exploration of the makeup of this final data set I will be working with, but for now I want to save a small sample of this DataFrame to share."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1471d1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_sample = total_df.sample(5)\n",
    "#total_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7df35eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_sample.to_csv('data_samples/FinalDF_Sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b670ea36",
   "metadata": {},
   "source": [
    "## Data Makeup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5565e4bd",
   "metadata": {},
   "source": [
    "At first I thought I might still need the userIDs, but I given all the columns I plan on adding for linguistic features, I don't think those IDs will be necessary, so my first order of business is to remove that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53bf46c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = total_df[['Text', 'Rating', 'Title', 'Author', 'Category', 'Genres', 'Language', 'Pages', 'Pub_Year', 'Avg_Rating', 'Ratings_Count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5fb362c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Text', 'Rating', 'Title', 'Author', 'Category', 'Genres', 'Language',\n",
       "       'Pages', 'Pub_Year', 'Avg_Rating', 'Ratings_Count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4acc6e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = total_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bbbec7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28274 entries, 0 to 28273\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Text           28274 non-null  object \n",
      " 1   Rating         28274 non-null  int64  \n",
      " 2   Title          28274 non-null  object \n",
      " 3   Author         28274 non-null  object \n",
      " 4   Category       28274 non-null  object \n",
      " 5   Genres         28274 non-null  object \n",
      " 6   Language       28274 non-null  object \n",
      " 7   Pages          28274 non-null  object \n",
      " 8   Pub_Year       28274 non-null  object \n",
      " 9   Avg_Rating     28274 non-null  float64\n",
      " 10  Ratings_Count  28274 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(8)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "total_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c7b2e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28274, 11)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bce6f7",
   "metadata": {},
   "source": [
    "I am working with a DataFrame of 28274 reviews and 11 total columns, though this will expand as I add more linguistic features.\n",
    "\n",
    "Now that that's done, let's take a look at some of the counts of different categories. What makeup of data am I finally working with?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd44e76c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ya                        4334\n",
       "fantasy_paranormal        4323\n",
       "romance                   3918\n",
       "mystery_thriller_crime    3789\n",
       "comics_graphic            3505\n",
       "history_bio               3362\n",
       "children                  2858\n",
       "poetry                    2185\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.Category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae41ee8d",
   "metadata": {},
   "source": [
    "Clearly there is a pretty wide range in the number of reviews left from each genre after some of the data cleaning. Each genre started out with 5000 reviews, but some were eliminated because they were non-English or empty, which disproportionately affected different genres. This will definitely be something to keep in mind during analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a0775a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    9941\n",
       "4    9593\n",
       "3    5356\n",
       "2    1807\n",
       "0     894\n",
       "1     683\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.Rating.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69efb9e9",
   "metadata": {},
   "source": [
    "5- and 4-star reviews are by far the most common, followed by 3-star reviews. 2-star reviews are much less frequent, and 1-star reviews even less. It makes sense that the higher ratings are more common as people are more likely to write a review about a book they like rather than a book they are indifferent about, but I'm a little surprised to see so few low ratings. In my experience, people tend to be pretty passionate about books they hate as well. If genre turns out to not be a significant factor changing linguistic features, it could be interesting to see if rating, which theoretically correlates to sentiment, has any effect on the language used in the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "195a8e33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17774"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_df.Title.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4198b71c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Milk and Honey                                                                          113\n",
       "Hamlet                                                                                   50\n",
       "The Giver (The Giver, #1)                                                                50\n",
       "The Hunger Games (The Hunger Games, #1)                                                  49\n",
       "Cinder (The Lunar Chronicles, #1)                                                        49\n",
       "The Girl on the Train                                                                    47\n",
       "Brown Girl Dreaming                                                                      44\n",
       "Wonder (Wonder #1)                                                                       43\n",
       "Miss Peregrine’s Home for Peculiar Children (Miss Peregrine’s Peculiar Children, #1)     42\n",
       "Divergent (Divergent, #1)                                                                40\n",
       "Where the Sidewalk Ends                                                                  40\n",
       "Gone Girl                                                                                37\n",
       "City of Bones (The Mortal Instruments, #1)                                               37\n",
       "Throne of Glass (Throne of Glass, #1)                                                    37\n",
       "The Fault in Our Stars                                                                   35\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.Title.value_counts()[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f4e4d5",
   "metadata": {},
   "source": [
    "Out of 28274 reviews, there are 17774 unique book titles that are reviewed, meaning 10500 reviews are repeat reviews of at least one book (a suspiciously even number), but still the majority of books are only reviewed once. Milk and Honey, a very popular book of poetry, is the most reviewed book at 113 reviews, and a lot of the other most reviewed books I recognize as Young Adult and Fantasy novels. Those were the top 2 genres with the most reviews that made the final cut, so it's not surprising there are more repeat reviews for these books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "078f8bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9688"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_df.Author.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c2d1852",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cassandra Clare     250\n",
       "Brian K. Vaughan    157\n",
       "Neil Gaiman         148\n",
       "Marissa Meyer       137\n",
       "Stephenie Meyer     130\n",
       "Rupi Kaur           127\n",
       "Sarah J. Maas       123\n",
       "Stephen King        123\n",
       "Rick Riordan        115\n",
       "Suzanne Collins     106\n",
       "Name: Author, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.Author.value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbe09b3",
   "metadata": {},
   "source": [
    "Out of 28274 reviews, there are only 9688 authors that are reviewed, which is a much smaller number, but makes sense seeing as authors may have written many different books. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f4c49dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eng      22737\n",
       "en-US     4268\n",
       "en-GB     1026\n",
       "en-CA      243\n",
       "Name: Language, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.Language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87f8c4b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Avg_Rating</th>\n",
       "      <th>Ratings_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28274.000000</td>\n",
       "      <td>28274.000000</td>\n",
       "      <td>2.827400e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.835396</td>\n",
       "      <td>3.990835</td>\n",
       "      <td>8.802585e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.221860</td>\n",
       "      <td>0.292023</td>\n",
       "      <td>3.506487e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.980000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.810000</td>\n",
       "      <td>5.360000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>4.224000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.190000</td>\n",
       "      <td>3.052450e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.899965e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Rating    Avg_Rating  Ratings_Count\n",
       "count  28274.000000  28274.000000   2.827400e+04\n",
       "mean       3.835396      3.990835   8.802585e+04\n",
       "std        1.221860      0.292023   3.506487e+05\n",
       "min        0.000000      1.980000   0.000000e+00\n",
       "25%        3.000000      3.810000   5.360000e+02\n",
       "50%        4.000000      4.010000   4.224000e+03\n",
       "75%        5.000000      4.190000   3.052450e+04\n",
       "max        5.000000      5.000000   4.899965e+06"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bff97fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">Rating</th>\n",
       "      <th colspan=\"5\" halign=\"left\">Avg_Rating</th>\n",
       "      <th colspan=\"8\" halign=\"left\">Ratings_Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>children</th>\n",
       "      <td>2858.0</td>\n",
       "      <td>3.904829</td>\n",
       "      <td>1.203209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2858.0</td>\n",
       "      <td>4.037768</td>\n",
       "      <td>...</td>\n",
       "      <td>4.21</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2858.0</td>\n",
       "      <td>93980.546186</td>\n",
       "      <td>275095.225792</td>\n",
       "      <td>1.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>3001.5</td>\n",
       "      <td>31387.00</td>\n",
       "      <td>1876252.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comics_graphic</th>\n",
       "      <td>3505.0</td>\n",
       "      <td>3.811412</td>\n",
       "      <td>1.153754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3505.0</td>\n",
       "      <td>4.021680</td>\n",
       "      <td>...</td>\n",
       "      <td>4.24</td>\n",
       "      <td>4.83</td>\n",
       "      <td>3505.0</td>\n",
       "      <td>16528.807703</td>\n",
       "      <td>41517.096041</td>\n",
       "      <td>1.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>2705.0</td>\n",
       "      <td>12834.00</td>\n",
       "      <td>406669.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fantasy_paranormal</th>\n",
       "      <td>4323.0</td>\n",
       "      <td>3.816100</td>\n",
       "      <td>1.246819</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4323.0</td>\n",
       "      <td>4.014464</td>\n",
       "      <td>...</td>\n",
       "      <td>4.23</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4323.0</td>\n",
       "      <td>108879.451076</td>\n",
       "      <td>375846.839796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>838.5</td>\n",
       "      <td>7755.0</td>\n",
       "      <td>55039.00</td>\n",
       "      <td>4765497.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>history_bio</th>\n",
       "      <td>3362.0</td>\n",
       "      <td>3.851279</td>\n",
       "      <td>1.215740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3362.0</td>\n",
       "      <td>3.943968</td>\n",
       "      <td>...</td>\n",
       "      <td>4.14</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3362.0</td>\n",
       "      <td>96545.556217</td>\n",
       "      <td>342835.065977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>592.0</td>\n",
       "      <td>4165.0</td>\n",
       "      <td>30058.75</td>\n",
       "      <td>3255518.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mystery_thriller_crime</th>\n",
       "      <td>3789.0</td>\n",
       "      <td>3.727105</td>\n",
       "      <td>1.178367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3789.0</td>\n",
       "      <td>3.884130</td>\n",
       "      <td>...</td>\n",
       "      <td>4.06</td>\n",
       "      <td>4.88</td>\n",
       "      <td>3789.0</td>\n",
       "      <td>59168.214568</td>\n",
       "      <td>210601.102517</td>\n",
       "      <td>1.0</td>\n",
       "      <td>522.0</td>\n",
       "      <td>3984.0</td>\n",
       "      <td>22034.00</td>\n",
       "      <td>2046499.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poetry</th>\n",
       "      <td>2185.0</td>\n",
       "      <td>3.897941</td>\n",
       "      <td>1.276413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2185.0</td>\n",
       "      <td>4.096256</td>\n",
       "      <td>...</td>\n",
       "      <td>4.26</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2185.0</td>\n",
       "      <td>44478.507551</td>\n",
       "      <td>151734.841123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>1433.0</td>\n",
       "      <td>15270.00</td>\n",
       "      <td>1029527.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>romance</th>\n",
       "      <td>3918.0</td>\n",
       "      <td>3.943849</td>\n",
       "      <td>1.212399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3918.0</td>\n",
       "      <td>4.000403</td>\n",
       "      <td>...</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.91</td>\n",
       "      <td>3918.0</td>\n",
       "      <td>32528.685299</td>\n",
       "      <td>143318.963490</td>\n",
       "      <td>1.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>1878.5</td>\n",
       "      <td>10393.00</td>\n",
       "      <td>2078406.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ya</th>\n",
       "      <td>4334.0</td>\n",
       "      <td>3.781034</td>\n",
       "      <td>1.272587</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4334.0</td>\n",
       "      <td>3.979213</td>\n",
       "      <td>...</td>\n",
       "      <td>4.17</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4334.0</td>\n",
       "      <td>211864.244347</td>\n",
       "      <td>652314.359248</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2863.5</td>\n",
       "      <td>19151.0</td>\n",
       "      <td>106182.00</td>\n",
       "      <td>4899965.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Rating                                               \\\n",
       "                         count      mean       std  min  25%  50%  75%  max   \n",
       "Category                                                                      \n",
       "children                2858.0  3.904829  1.203209  0.0  3.0  4.0  5.0  5.0   \n",
       "comics_graphic          3505.0  3.811412  1.153754  0.0  3.0  4.0  5.0  5.0   \n",
       "fantasy_paranormal      4323.0  3.816100  1.246819  0.0  3.0  4.0  5.0  5.0   \n",
       "history_bio             3362.0  3.851279  1.215740  0.0  3.0  4.0  5.0  5.0   \n",
       "mystery_thriller_crime  3789.0  3.727105  1.178367  0.0  3.0  4.0  5.0  5.0   \n",
       "poetry                  2185.0  3.897941  1.276413  0.0  3.0  4.0  5.0  5.0   \n",
       "romance                 3918.0  3.943849  1.212399  0.0  3.0  4.0  5.0  5.0   \n",
       "ya                      4334.0  3.781034  1.272587  0.0  3.0  4.0  5.0  5.0   \n",
       "\n",
       "                       Avg_Rating            ...             Ratings_Count  \\\n",
       "                            count      mean  ...   75%   max         count   \n",
       "Category                                     ...                             \n",
       "children                   2858.0  4.037768  ...  4.21  5.00        2858.0   \n",
       "comics_graphic             3505.0  4.021680  ...  4.24  4.83        3505.0   \n",
       "fantasy_paranormal         4323.0  4.014464  ...  4.23  5.00        4323.0   \n",
       "history_bio                3362.0  3.943968  ...  4.14  5.00        3362.0   \n",
       "mystery_thriller_crime     3789.0  3.884130  ...  4.06  4.88        3789.0   \n",
       "poetry                     2185.0  4.096256  ...  4.26  5.00        2185.0   \n",
       "romance                    3918.0  4.000403  ...  4.20  4.91        3918.0   \n",
       "ya                         4334.0  3.979213  ...  4.17  5.00        4334.0   \n",
       "\n",
       "                                                                            \\\n",
       "                                 mean            std  min     25%      50%   \n",
       "Category                                                                     \n",
       "children                 93980.546186  275095.225792  1.0   330.0   3001.5   \n",
       "comics_graphic           16528.807703   41517.096041  1.0   479.0   2705.0   \n",
       "fantasy_paranormal      108879.451076  375846.839796  1.0   838.5   7755.0   \n",
       "history_bio              96545.556217  342835.065977  0.0   592.0   4165.0   \n",
       "mystery_thriller_crime   59168.214568  210601.102517  1.0   522.0   3984.0   \n",
       "poetry                   44478.507551  151734.841123  0.0   148.0   1433.0   \n",
       "romance                  32528.685299  143318.963490  1.0   333.0   1878.5   \n",
       "ya                      211864.244347  652314.359248  1.0  2863.5  19151.0   \n",
       "\n",
       "                                              \n",
       "                              75%        max  \n",
       "Category                                      \n",
       "children                 31387.00  1876252.0  \n",
       "comics_graphic           12834.00   406669.0  \n",
       "fantasy_paranormal       55039.00  4765497.0  \n",
       "history_bio              30058.75  3255518.0  \n",
       "mystery_thriller_crime   22034.00  2046499.0  \n",
       "poetry                   15270.00  1029527.0  \n",
       "romance                  10393.00  2078406.0  \n",
       "ya                      106182.00  4899965.0  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.groupby('Category').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7764f4d6",
   "metadata": {},
   "source": [
    "Most interesting here is to look at the mean rating for each genre. They're pretty close together, but Romance has the highest average rating of 3.94 and Mystery/Thriller/Crime has the lowest average rating of 3.73. It's also intersting to compare the average ratings from these reviews to the Avg_Rating column statistics, which is the average rating of the book being reviewed. In general, the sample of reviews I am analyzing rate the book slightly lower than its average rating from all reviews, which is just an interesting phenomenon. In general, all Goodreads reviewers (not just from this data set) seem to rate books in the Poetry genre highest (4.26) and Mystery/Thriller/Crime books lowest (4.06). Finally, the ratings count shows the number of ratings each book had (again, not just the UCSD data), so it appears that the books of the Young Adult genre represented by the UCSD corpus has by far the most ratings on Goodreads (211864) and books of the Comics/Graphic genre have the least (16529). It could be interesting to look at genres with a lower ratings count but higher reviews count, which suggests that it is a more niche genre that appeals to a more specific type of reader."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afba00e",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "Now that I've FINALLY got my final data set and a sense of its size and makeup, it's time to start analysis! Since I'm looking at overall linguistic differences between reviews for different genres, I want to include as many different linguistic features as I can think of. In this next secion, I will be adding those features as additional columns to the DataFrame so I can then analayze their differences between genre categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f154dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "%pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4853d09",
   "metadata": {},
   "source": [
    "### Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10ac2242",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j9/9lmff3zj6bxgfpsb8gm8pjrw0000gn/T/ipykernel_90463/19419265.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['Toks'] = test_df.Text.map(nltk.word_tokenize)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                                  [O]\n",
       "1        [my, pick, for, the, caldecott, so, far, ...]\n",
       "2    [This, time, Dan, and, Amy, go, to, the, Baham...\n",
       "3    [Loved, the, excerpts, where, Julia, ,, the, m...\n",
       "4    [I, liked, the, illustrations, ,, which, are, ...\n",
       "Name: Toks, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = total_df.head()\n",
    "test_df['Toks'] = test_df.Text.map(nltk.word_tokenize)\n",
    "test_df['Toks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f21c38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Category</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Language</th>\n",
       "      <th>Pages</th>\n",
       "      <th>Pub_Year</th>\n",
       "      <th>Avg_Rating</th>\n",
       "      <th>Ratings_Count</th>\n",
       "      <th>Toks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>Xander's Panda Party</td>\n",
       "      <td>Linda Sue Park</td>\n",
       "      <td>children</td>\n",
       "      <td>{'children': 143, 'fiction': 15, 'poetry': 9, ...</td>\n",
       "      <td>eng</td>\n",
       "      <td>40</td>\n",
       "      <td>2013</td>\n",
       "      <td>4.05</td>\n",
       "      <td>1163</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my pick for the caldecott so far...</td>\n",
       "      <td>5</td>\n",
       "      <td>Xander's Panda Party</td>\n",
       "      <td>Linda Sue Park</td>\n",
       "      <td>children</td>\n",
       "      <td>{'children': 143, 'fiction': 15, 'poetry': 9, ...</td>\n",
       "      <td>eng</td>\n",
       "      <td>40</td>\n",
       "      <td>2013</td>\n",
       "      <td>4.05</td>\n",
       "      <td>1163</td>\n",
       "      <td>[my, pick, for, the, caldecott, so, far, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This time Dan and Amy go to the Bahamas and Ja...</td>\n",
       "      <td>4</td>\n",
       "      <td>Storm Warning (The 39 Clues, #9)</td>\n",
       "      <td>Linda Sue Park</td>\n",
       "      <td>children</td>\n",
       "      <td>{'mystery, thriller, crime': 188, 'young-adult...</td>\n",
       "      <td>eng</td>\n",
       "      <td>190</td>\n",
       "      <td>2010</td>\n",
       "      <td>3.98</td>\n",
       "      <td>39904</td>\n",
       "      <td>[This, time, Dan, and, Amy, go, to, the, Baham...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Loved the excerpts where Julia, the main chara...</td>\n",
       "      <td>5</td>\n",
       "      <td>Project Mulberry</td>\n",
       "      <td>Linda Sue Park</td>\n",
       "      <td>children</td>\n",
       "      <td>{'fiction': 122, 'children': 111, 'young-adult...</td>\n",
       "      <td>eng</td>\n",
       "      <td>240</td>\n",
       "      <td>2007</td>\n",
       "      <td>3.67</td>\n",
       "      <td>2929</td>\n",
       "      <td>[Loved, the, excerpts, where, Julia, ,, the, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I liked the illustrations, which are are - wel...</td>\n",
       "      <td>4</td>\n",
       "      <td>A Moon of My Own</td>\n",
       "      <td>Jennifer Rustgi</td>\n",
       "      <td>children</td>\n",
       "      <td>{'children': 13, 'young-adult': 2, 'non-fictio...</td>\n",
       "      <td>eng</td>\n",
       "      <td>32</td>\n",
       "      <td>2016</td>\n",
       "      <td>3.78</td>\n",
       "      <td>84</td>\n",
       "      <td>[I, liked, the, illustrations, ,, which, are, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Rating  \\\n",
       "0                                                  O       0   \n",
       "1                my pick for the caldecott so far...       5   \n",
       "2  This time Dan and Amy go to the Bahamas and Ja...       4   \n",
       "3  Loved the excerpts where Julia, the main chara...       5   \n",
       "4  I liked the illustrations, which are are - wel...       4   \n",
       "\n",
       "                              Title           Author  Category  \\\n",
       "0              Xander's Panda Party   Linda Sue Park  children   \n",
       "1              Xander's Panda Party   Linda Sue Park  children   \n",
       "2  Storm Warning (The 39 Clues, #9)   Linda Sue Park  children   \n",
       "3                  Project Mulberry   Linda Sue Park  children   \n",
       "4                  A Moon of My Own  Jennifer Rustgi  children   \n",
       "\n",
       "                                              Genres Language Pages Pub_Year  \\\n",
       "0  {'children': 143, 'fiction': 15, 'poetry': 9, ...      eng    40     2013   \n",
       "1  {'children': 143, 'fiction': 15, 'poetry': 9, ...      eng    40     2013   \n",
       "2  {'mystery, thriller, crime': 188, 'young-adult...      eng   190     2010   \n",
       "3  {'fiction': 122, 'children': 111, 'young-adult...      eng   240     2007   \n",
       "4  {'children': 13, 'young-adult': 2, 'non-fictio...      eng    32     2016   \n",
       "\n",
       "   Avg_Rating  Ratings_Count  \\\n",
       "0        4.05           1163   \n",
       "1        4.05           1163   \n",
       "2        3.98          39904   \n",
       "3        3.67           2929   \n",
       "4        3.78             84   \n",
       "\n",
       "                                                Toks  \n",
       "0                                                [O]  \n",
       "1      [my, pick, for, the, caldecott, so, far, ...]  \n",
       "2  [This, time, Dan, and, Amy, go, to, the, Baham...  \n",
       "3  [Loved, the, excerpts, where, Julia, ,, the, m...  \n",
       "4  [I, liked, the, illustrations, ,, which, are, ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df['Toks'] = total_df.Text.map(nltk.word_tokenize)\n",
    "total_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "903f076f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j9/9lmff3zj6bxgfpsb8gm8pjrw0000gn/T/ipykernel_90463/780036847.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['Toks_Lower'] = test_df.Toks.map(lambda x: [word.lower() for word in x])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                                  [o]\n",
       "1        [my, pick, for, the, caldecott, so, far, ...]\n",
       "2    [this, time, dan, and, amy, go, to, the, baham...\n",
       "3    [loved, the, excerpts, where, julia, ,, the, m...\n",
       "4    [i, liked, the, illustrations, ,, which, are, ...\n",
       "Name: Toks_Lower, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Toks_Lower'] = test_df.Toks.map(lambda x: [word.lower() for word in x])\n",
    "test_df['Toks_Lower']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb842eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df['Toks_Lower'] = total_df.Toks.map(lambda x: [word.lower() for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8635220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'time', 'dan', 'and', 'amy', 'go', 'to', 'the', 'bahamas', 'and', 'jamaica', 'to', 'discover', 'the', 'truth', 'about', 'the', 'madrigals', '.', 'they', 'find', 'the', 'clue', 'to', 'the', 'next', 'country', 'which', 'may', 'yet', 'unify', 'the', 'cahills', 'once', 'again']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.Toks_Lower.iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78af50e1",
   "metadata": {},
   "source": [
    "### Token Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be63de2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j9/9lmff3zj6bxgfpsb8gm8pjrw0000gn/T/ipykernel_90463/1246011675.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['Tok_Count'] = test_df.Toks.map(len)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      8\n",
       "2     35\n",
       "3     18\n",
       "4    153\n",
       "Name: Tok_Count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Tok_Count'] = test_df.Toks.map(len)\n",
    "test_df['Tok_Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e15dee82",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df['Tok_Count'] = total_df.Toks.map(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc072d5b",
   "metadata": {},
   "source": [
    "### Word Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01e68cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j9/9lmff3zj6bxgfpsb8gm8pjrw0000gn/T/ipykernel_90463/1037107477.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['Avg_Word_Len'] = test_df.Toks.map(lambda x: np.mean([len(w) for w in x if w.isalnum()]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1.000000\n",
       "1    3.714286\n",
       "2    4.176471\n",
       "3    5.000000\n",
       "4    4.484375\n",
       "Name: Avg_Word_Len, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Avg_Word_Len'] = test_df.Toks.map(lambda x: np.mean([len(w) for w in x if w.isalnum()]))\n",
    "test_df['Avg_Word_Len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e87ce0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my', 'pick', 'for', 'the', 'caldecott', 'so', 'far', '...']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.Toks.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "646967d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashleyfeiler/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/ashleyfeiler/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "total_df['Avg_Word_Len'] = total_df.Toks.map(lambda x: np.mean([len(w) for w in x if w.isalnum()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735e3e22",
   "metadata": {},
   "source": [
    "### Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4fcee793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j9/9lmff3zj6bxgfpsb8gm8pjrw0000gn/T/ipykernel_90463/738031235.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['Sents'] = test_df.Text.map(nltk.sent_tokenize)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                                  [O]\n",
       "1                [my pick for the caldecott so far...]\n",
       "2    [This time Dan and Amy go to the Bahamas and J...\n",
       "3    [Loved the excerpts where Julia, the main char...\n",
       "4    [I liked the illustrations, which are are - we...\n",
       "Name: Sents, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Sents'] = test_df.Text.map(nltk.sent_tokenize)\n",
    "test_df['Sents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "302dae5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This time Dan and Amy go to the Bahamas and Jamaica to discover the truth about the Madrigals.', 'They find the clue to the next country which may yet unify the Cahills once again']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.Sents.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "857d1343",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df['Sents'] = total_df.Text.map(nltk.sent_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f60a351",
   "metadata": {},
   "source": [
    "### Sentence Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e48af4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j9/9lmff3zj6bxgfpsb8gm8pjrw0000gn/T/ipykernel_90463/1611349258.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['Sents_Count'] = test_df.Sents.map(len)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    2\n",
       "3    1\n",
       "4    5\n",
       "Name: Sents_Count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Sents_Count'] = test_df.Sents.map(len)\n",
    "test_df['Sents_Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5293db9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df['Sents_Count'] = total_df.Sents.map(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a9acd0",
   "metadata": {},
   "source": [
    "### Sentence Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a7fc3541",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j9/9lmff3zj6bxgfpsb8gm8pjrw0000gn/T/ipykernel_90463/17652353.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['Avg_Sent_Len'] = test_df.Sents.map(lambda x: np.mean([len(nltk.word_tokenize(s)) for s in x]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     1.0\n",
       "1     8.0\n",
       "2    17.5\n",
       "3    18.0\n",
       "4    30.6\n",
       "Name: Avg_Sent_Len, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Had to tokenize first\n",
    "test_df['Avg_Sent_Len'] = test_df.Sents.map(lambda x: np.mean([len(nltk.word_tokenize(s)) for s in x]))\n",
    "test_df['Avg_Sent_Len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "68d800f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df['Avg_Sent_Len'] = total_df.Sents.map(lambda x: np.mean([len(nltk.word_tokenize(s)) for s in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "398412a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Avg_Rating</th>\n",
       "      <th>Ratings_Count</th>\n",
       "      <th>Tok_Count</th>\n",
       "      <th>Avg_Word_Len</th>\n",
       "      <th>Sents_Count</th>\n",
       "      <th>Avg_Sent_Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28274.000000</td>\n",
       "      <td>28274.000000</td>\n",
       "      <td>2.827400e+04</td>\n",
       "      <td>28274.000000</td>\n",
       "      <td>28118.000000</td>\n",
       "      <td>28274.000000</td>\n",
       "      <td>28274.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.835396</td>\n",
       "      <td>3.990835</td>\n",
       "      <td>8.802585e+04</td>\n",
       "      <td>137.824680</td>\n",
       "      <td>4.326438</td>\n",
       "      <td>7.525005</td>\n",
       "      <td>16.558581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.221860</td>\n",
       "      <td>0.292023</td>\n",
       "      <td>3.506487e+05</td>\n",
       "      <td>201.674042</td>\n",
       "      <td>0.715024</td>\n",
       "      <td>10.178012</td>\n",
       "      <td>10.228095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.980000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.810000</td>\n",
       "      <td>5.360000e+02</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>4.224000e+03</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>4.251969</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.190000</td>\n",
       "      <td>3.052450e+04</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>4.540541</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>20.885440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.899965e+06</td>\n",
       "      <td>4159.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>388.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Rating    Avg_Rating  Ratings_Count     Tok_Count  Avg_Word_Len  \\\n",
       "count  28274.000000  28274.000000   2.827400e+04  28274.000000  28118.000000   \n",
       "mean       3.835396      3.990835   8.802585e+04    137.824680      4.326438   \n",
       "std        1.221860      0.292023   3.506487e+05    201.674042      0.715024   \n",
       "min        0.000000      1.980000   0.000000e+00      1.000000      1.000000   \n",
       "25%        3.000000      3.810000   5.360000e+02     26.000000      4.000000   \n",
       "50%        4.000000      4.010000   4.224000e+03     66.000000      4.251969   \n",
       "75%        5.000000      4.190000   3.052450e+04    164.000000      4.540541   \n",
       "max        5.000000      5.000000   4.899965e+06   4159.000000     16.000000   \n",
       "\n",
       "        Sents_Count  Avg_Sent_Len  \n",
       "count  28274.000000  28274.000000  \n",
       "mean       7.525005     16.558581  \n",
       "std       10.178012     10.228095  \n",
       "min        1.000000      1.000000  \n",
       "25%        2.000000     10.750000  \n",
       "50%        4.000000     15.714286  \n",
       "75%        9.000000     20.885440  \n",
       "max      210.000000    388.000000  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e88c870f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Category</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Language</th>\n",
       "      <th>Pages</th>\n",
       "      <th>Pub_Year</th>\n",
       "      <th>Avg_Rating</th>\n",
       "      <th>Ratings_Count</th>\n",
       "      <th>Toks</th>\n",
       "      <th>Toks_Lower</th>\n",
       "      <th>Tok_Count</th>\n",
       "      <th>Avg_Word_Len</th>\n",
       "      <th>Sents</th>\n",
       "      <th>Sents_Count</th>\n",
       "      <th>Avg_Sent_Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26450</th>\n",
       "      <td>The Knight's Tale \\n Very tragic, romantic sto...</td>\n",
       "      <td>4</td>\n",
       "      <td>The Canterbury Tales</td>\n",
       "      <td>Geoffrey Chaucer</td>\n",
       "      <td>poetry</td>\n",
       "      <td>{'poetry': 1659, 'fiction': 613, 'history, his...</td>\n",
       "      <td>eng</td>\n",
       "      <td>627</td>\n",
       "      <td>1934</td>\n",
       "      <td>3.48</td>\n",
       "      <td>16</td>\n",
       "      <td>[The, Knight, 's, Tale, Very, tragic, ,, roman...</td>\n",
       "      <td>[the, knight, 's, tale, very, tragic, ,, roman...</td>\n",
       "      <td>4159</td>\n",
       "      <td>4.239285</td>\n",
       "      <td>[The Knight's Tale \\n Very tragic, romantic st...</td>\n",
       "      <td>196</td>\n",
       "      <td>21.219388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Rating  \\\n",
       "26450  The Knight's Tale \\n Very tragic, romantic sto...       4   \n",
       "\n",
       "                      Title            Author Category  \\\n",
       "26450  The Canterbury Tales  Geoffrey Chaucer   poetry   \n",
       "\n",
       "                                                  Genres Language Pages  \\\n",
       "26450  {'poetry': 1659, 'fiction': 613, 'history, his...      eng   627   \n",
       "\n",
       "      Pub_Year  Avg_Rating  Ratings_Count  \\\n",
       "26450     1934        3.48             16   \n",
       "\n",
       "                                                    Toks  \\\n",
       "26450  [The, Knight, 's, Tale, Very, tragic, ,, roman...   \n",
       "\n",
       "                                              Toks_Lower  Tok_Count  \\\n",
       "26450  [the, knight, 's, tale, very, tragic, ,, roman...       4159   \n",
       "\n",
       "       Avg_Word_Len                                              Sents  \\\n",
       "26450      4.239285  [The Knight's Tale \\n Very tragic, romantic st...   \n",
       "\n",
       "       Sents_Count  Avg_Sent_Len  \n",
       "26450          196     21.219388  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large = (total_df.Tok_Count > 4000) \n",
    "total_df[large]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f615b4",
   "metadata": {},
   "source": [
    "This review should be considered a book in and of itself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c7e8b629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 18)\n",
      "(221, 18)\n",
      "(1521, 18)\n"
     ]
    }
   ],
   "source": [
    "large = (total_df.Tok_Count > 3000) \n",
    "print(total_df[large].shape)\n",
    "\n",
    "large = (total_df.Tok_Count > 1000) \n",
    "print(total_df[large].shape)\n",
    "\n",
    "large = (total_df.Tok_Count > 500) \n",
    "print(total_df[large].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745725fb",
   "metadata": {},
   "source": [
    "I'm gonna skip TTR for because I'd have to take a tiny sample of some of the longer texts to get to a comparable point to the smaller reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99c7a28",
   "metadata": {},
   "source": [
    "### Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f83aa414",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I loved this book!!!\n",
      "{'neg': 0.0, 'neu': 0.295, 'pos': 0.705, 'compound': 0.6981}\n",
      "positive\n",
      "5\n",
      "\n",
      "Boring.\n",
      "{'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound': -0.3182}\n",
      "negative\n",
      "2\n",
      "\n",
      "This book was ok - not my favorite, but not the worst\n",
      "{'neg': 0.11, 'neu': 0.507, 'pos': 0.383, 'compound': 0.6487}\n",
      "positive\n",
      "5\n",
      "\n",
      "My heart after reading this book: :) <3\n",
      "{'neg': 0.0, 'neu': 0.504, 'pos': 0.496, 'compound': 0.7096}\n",
      "positive\n",
      "5\n",
      "\n",
      "Literally the worst book I've ever read\n",
      "{'neg': 0.406, 'neu': 0.594, 'pos': 0.0, 'compound': -0.6249}\n",
      "negative\n",
      "1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#nltk.download('vader_lexicon')\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "sentiment = SentimentIntensityAnalyzer()\n",
    "\n",
    "test_sents = [\"I loved this book!!!\", \n",
    "             \"Boring.\", \n",
    "             \"This book was ok - not my favorite, but not the worst\",\n",
    "             \"My heart after reading this book: :) <3\",\n",
    "             \"Literally the worst book I've ever read\"]\n",
    "\n",
    "for sent in test_sents:\n",
    "    print(sent)\n",
    "    print(sentiment.polarity_scores(sent))\n",
    "    compound = sentiment.polarity_scores(sent)['compound']\n",
    "    if compound > 0:\n",
    "        print('positive')\n",
    "    elif compound < 0:\n",
    "        print('negative')\n",
    "    elif compound == 0:\n",
    "        print('neutral')\n",
    "        \n",
    "    if compound >= -1 and compound < -0.6:\n",
    "        print('1\\n')\n",
    "    elif compound >= -0.6 and compound < -0.2:\n",
    "        print('2\\n')\n",
    "    elif compound >= -0.2 and compound < 0.2:\n",
    "        print('3\\n')\n",
    "    elif compound >= 0.2 and compound < 0.6:\n",
    "        print('4\\n')\n",
    "    elif compound >= 0.6:\n",
    "        print('5\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b14a71e",
   "metadata": {},
   "source": [
    "Numerical rankings don't seem to be the most accurate, so for right now I'll just stick with positive/negative tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cd11fad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j9/9lmff3zj6bxgfpsb8gm8pjrw0000gn/T/ipykernel_90463/306129234.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['Sentiment_Num'] = test_df.Sents.map(sent_analysis)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.00000\n",
       "1    0.00000\n",
       "2    0.15910\n",
       "3    0.59940\n",
       "4    0.44342\n",
       "Name: Sentiment_Num, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sent_analysis(sents):\n",
    "    scores = [sentiment.polarity_scores(sent)['compound'] for sent in sents]\n",
    "    average = np.mean(scores)\n",
    "    return average\n",
    "\n",
    "test_df['Sentiment_Num'] = test_df.Sents.map(sent_analysis)\n",
    "test_df.Sentiment_Num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c488fb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df['Sentiment_Num'] = total_df.Sents.map(sent_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6804840c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment.polarity_scores(test_df.Text.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d03fcad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j9/9lmff3zj6bxgfpsb8gm8pjrw0000gn/T/ipykernel_90463/751213680.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['Sentiment_Tag'] = test_df.Sentiment_Num.map(tag_sentiment)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     neutral\n",
       "1     neutral\n",
       "2    positive\n",
       "3    positive\n",
       "4    positive\n",
       "Name: Sentiment_Tag, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tag_sentiment(score):\n",
    "    if score > 0:\n",
    "        tag = 'positive'\n",
    "    elif score < 0:\n",
    "        tag = 'negative'\n",
    "    else:\n",
    "        tag = 'neutral'\n",
    "    \n",
    "    return tag\n",
    "\n",
    "test_df['Sentiment_Tag'] = test_df.Sentiment_Num.map(tag_sentiment)\n",
    "test_df.Sentiment_Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6e000d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df['Sentiment_Tag'] = total_df.Sentiment_Num.map(tag_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9bd2d287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Avg_Rating</th>\n",
       "      <th>Ratings_Count</th>\n",
       "      <th>Tok_Count</th>\n",
       "      <th>Avg_Word_Len</th>\n",
       "      <th>Sents_Count</th>\n",
       "      <th>Avg_Sent_Len</th>\n",
       "      <th>Sentiment_Num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28274.000000</td>\n",
       "      <td>28274.000000</td>\n",
       "      <td>2.827400e+04</td>\n",
       "      <td>28274.000000</td>\n",
       "      <td>28118.000000</td>\n",
       "      <td>28274.000000</td>\n",
       "      <td>28274.000000</td>\n",
       "      <td>28274.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.835396</td>\n",
       "      <td>3.990835</td>\n",
       "      <td>8.802585e+04</td>\n",
       "      <td>137.824680</td>\n",
       "      <td>4.326438</td>\n",
       "      <td>7.525005</td>\n",
       "      <td>16.558581</td>\n",
       "      <td>0.234953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.221860</td>\n",
       "      <td>0.292023</td>\n",
       "      <td>3.506487e+05</td>\n",
       "      <td>201.674042</td>\n",
       "      <td>0.715024</td>\n",
       "      <td>10.178012</td>\n",
       "      <td>10.228095</td>\n",
       "      <td>0.272964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.980000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.949300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.810000</td>\n",
       "      <td>5.360000e+02</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.750000</td>\n",
       "      <td>0.038188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>4.224000e+03</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>4.251969</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.714286</td>\n",
       "      <td>0.229155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.190000</td>\n",
       "      <td>3.052450e+04</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>4.540541</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>20.885440</td>\n",
       "      <td>0.417267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.899965e+06</td>\n",
       "      <td>4159.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>388.000000</td>\n",
       "      <td>0.990300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Rating    Avg_Rating  Ratings_Count     Tok_Count  Avg_Word_Len  \\\n",
       "count  28274.000000  28274.000000   2.827400e+04  28274.000000  28118.000000   \n",
       "mean       3.835396      3.990835   8.802585e+04    137.824680      4.326438   \n",
       "std        1.221860      0.292023   3.506487e+05    201.674042      0.715024   \n",
       "min        0.000000      1.980000   0.000000e+00      1.000000      1.000000   \n",
       "25%        3.000000      3.810000   5.360000e+02     26.000000      4.000000   \n",
       "50%        4.000000      4.010000   4.224000e+03     66.000000      4.251969   \n",
       "75%        5.000000      4.190000   3.052450e+04    164.000000      4.540541   \n",
       "max        5.000000      5.000000   4.899965e+06   4159.000000     16.000000   \n",
       "\n",
       "        Sents_Count  Avg_Sent_Len  Sentiment_Num  \n",
       "count  28274.000000  28274.000000   28274.000000  \n",
       "mean       7.525005     16.558581       0.234953  \n",
       "std       10.178012     10.228095       0.272964  \n",
       "min        1.000000      1.000000      -0.949300  \n",
       "25%        2.000000     10.750000       0.038188  \n",
       "50%        4.000000     15.714286       0.229155  \n",
       "75%        9.000000     20.885440       0.417267  \n",
       "max      210.000000    388.000000       0.990300  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
