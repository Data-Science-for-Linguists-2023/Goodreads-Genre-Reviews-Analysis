## Progress Report
### Initial Entry - 2/12/23
- Created public GitHub repository to house all files related to my project
- Initialized README file, License placeholder, and .gitignore file
- Proposed detailed project plan including plans for data source and collection, analysis, and presentation of findings

### 1st Progress Report - 2/24/23
I explored the [UCSD Goodreads data](https://sites.google.com/eng.ucsd.edu/ucsdbookgraph/home#h.p_VCP_qovwtnn1), getting a better understanding of the intention of the original study for which the data was collected, as well as what kinds of files I would need given that the corpus is so comprehensive. In [Jupyter Notebook](https://github.com/Data-Science-for-Linguists-2023/Goodreads-Genre-Reviews-Analysis/blob/main/Data_Exploration.ipynb), I chose to explore the content of the first genre subset, Children’s Literature, to better understand the structure and contents of the data before trying to clean all the data. Using columns that matched across files, I merged review, book, genre and author data files  to get all the necessary information about each review into one DataFrame. I then filtered the data to include only reviews for books in English and exclue rows that had filled either the review text or rating with an empty string. Finally, I took a sample of 1000 of the remaining reviews. I repeated this process with two additional genres, Poetry and Comics/Graphic Novels, and then appended all the samples into one DataFrame. However, I did have trouble getting Jupyter Notebook to handle larger JSON files for other genres, so I wrote out the code for the remaining genres without running it (for now). 

**Data Sharing Plan:** Because the data I am using comes from the UCSD corpus which explicitly states that the data is only for academic use and not to be redistributed, I cannot share the entire data source. That being said, I will be sticking to that Fair Use guidelines that allow me to share a very small portion of the data. Because I showed the first 5 entries of the DataFrame quite frequently within my Data Exploration Jupyter Notebook, I have created a [data_samples directory](https://github.com/Data-Science-for-Linguists-2023/Goodreads-Genre-Reviews-Analysis/tree/main/data_samples) that includes the first 5 entries of all the genre subsets I've compiled so far (3 currently, but will be 8 total) as pulled directly from the UCSD data. Once I have my CSV files of the sampled reviews, I would like to include the same sized portion of that data as well given that that is the portion of the data I will be using for the analysis. 

### 2nd Progress Report - 3/23/23
This month, I struggled to find a way to load my data into Jupyter Notebook given the large size of the files. After some failed experiments with various methods of memory conservation, I resorted to sampling 5000 reviews from each genre's data set through command line so I would have files short enough for my computer to handle. I had to scrap my original plan to get even samples from each genre, instead processing the data from each of the genre samples using the steps from Progress Report #1. This resulted in slightly uneven samples across genres. The original Data Exploration notebook can be found [here](https://github.com/Data-Science-for-Linguists-2023/Goodreads-Genre-Reviews-Analysis/blob/main/Data_Exploration.ipynb), and the additional data processing notebooks can be found in the [data_prep folder](https://github.com/Data-Science-for-Linguists-2023/Goodreads-Genre-Reviews-Analysis/tree/main/data_prep). I then pickled the resulting DataFrame from each genre to then combine into a final DataFrame in a [new continuing Jupyter Notebook](https://github.com/Data-Science-for-Linguists-2023/Goodreads-Genre-Reviews-Analysis/blob/main/Compiling_Data.ipynb) on which I will do the rest of my analysis. To get started with the analysis, I added a bunch of columns to my DataFrame holding different linguistic features such as token/sentence count, average word/sentence length, and sentiment.

**Data Sharing Plan:**
My data sharing plan is pretty much the same as before. The owners of the UCSD Goodreads data specified in plain language that it can be used for academic purposes but cannot be redistributed, so I will be sharing very small samples as allowed under Fair Use just to give a sense of the data. In the [data_samples folder](https://github.com/Data-Science-for-Linguists-2023/Goodreads-Genre-Reviews-Analysis/tree/main/data_samples), I have one CSV file with a sample 5 reviews in their original format from assorted genres, as well as a sample of 5 reviews from my final aggregated DataFrame to show what the final data I am analyzing looks like. The original data set has over 15 million reviews, so these data samples are a tiny fraction of the overall data set. I also limited how frequently I flashed the heads of my DataFrames within the code itself.

**Licensing:**
While I am unable to make my data publicly available other than the small samples, I would like to make the rest of the code in my repository publicly available should anyone else find the data cleaning or analysis process helpful. I chose to use the [GNU GPLv3 license](https://choosealicense.com/licenses/gpl-3.0/), which makes my code available to the public to use and modify granted that my original work is credited and any changes future users make are announced.

### 3rd Progress Report - 4/10/23
To keep things clean, I conducted my analysis in a [new continuing Jupyter Notebook](https://github.com/Data-Science-for-Linguists-2023/Goodreads-Genre-Reviews-Analysis/blob/main/Data_Analysis.ipynb), although I did make some slight edits to my [Compiling Data notebook](https://github.com/Data-Science-for-Linguists-2023/Goodreads-Genre-Reviews-Analysis/blob/main/Compiling_Data.ipynb) to deal with nonsense text and add tags for part of speech. Since my goal was to figure out in what ways the reviews of different genres differed linguistically, for my analysis, I began by looking at the breakdown of each specific feature and how that feature varied across genres. I created visuals and conducted statistical tests to determine if the differences across genres was significant so I knew which features to focus further analysis on. In general, I found that some of the most significant features were token and sentence count, sentiment score, and adjective count, with more detailed analysis comments found within the [Data Analysis notebook](https://github.com/Data-Science-for-Linguists-2023/Goodreads-Genre-Reviews-Analysis/blob/main/Data_Analysis.ipynb). I also began using some machine learning techniques to analyze the linguistic features of the reviews, which I plan to do more of before my final presentation. I used cluster modeling to have the model determine 8 topics (trying to reflect the 8 genres). It was not very successful, but did seem to vaguely recognize Poetry or Romance and Mystery/Thriller/Crime as topics.

**Data Update:**
There have been no new changes to my data files since the last progress report. However, I want to clarify the thought process in choosing what data I would be working with. Given the massive size of the data set I originally started with, the data cleaning process turned out to be much more complex than I originally anticipated. Therefore I chose to adapt my original project plan where I intended to scrape Goodreads for additional reviews to augment the data with additional genres - instead I stuck to just the UCSD data and focused my efforts on properly cleaning the data and then using taggers for sentiment and part of speech to add additional information in my analysis section. The data samples, along with my cleaned final dataframe used for analysis, can be found [here](https://github.com/Data-Science-for-Linguists-2023/Goodreads-Genre-Reviews-Analysis/tree/main/data_samples).

### Citations:

[Fine-Grained Spoiler Detection from Large-Scale Review Corpora](https://aclanthology.org/P19-1248) (Wan et al., ACL 2019)

Mengting Wan and Julian McAuley. 2018. Item recommendation on monotonic behavior chains. In Proceedings of the 12th ACM Conference on Recommender Systems (RecSys '18). Association for Computing Machinery, New York, NY, USA, 86–94. <https://doi.org/10.1145/3240323.3240369>

Hutto, C.J. & Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. Eighth International Conference on Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014.

